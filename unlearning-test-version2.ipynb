{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MACHINE UNLEARNING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/2gycpkq57p97cpwvmwvm69m00000gn/T/ipykernel_3251/2126072653.py:20: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import variational\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from itertools import cycle\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from typing import List\n",
    "import itertools\n",
    "from tqdm.autonotebook import tqdm\n",
    "from models import *\n",
    "import models\n",
    "from logger import *\n",
    "import wandb\n",
    "from thirdparty.repdistiller.helper.util import adjust_learning_rate as sgda_adjust_learning_rate\n",
    "from thirdparty.repdistiller.distiller_zoo import DistillKL, HintLoss, Attention, Similarity, Correlation, VIDLoss, RKDLoss\n",
    "from thirdparty.repdistiller.distiller_zoo import PKT, ABLoss, FactorTransfer, KDSVD, FSP, NSTLoss\n",
    "from thirdparty.repdistiller.helper.loops import train_distill, train_distill_hide, train_distill_linear, train_vanilla, train_negrad, train_bcu, train_bcu_distill, validate\n",
    "from thirdparty.repdistiller.helper.pretrain import init\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Original Model\n",
    "\n",
    "This cell will run main.py which generate a model and leave many checkpoints for later references. We\n",
    "prepare standard_model_for_pilot for the sake of pilot.\n",
    "\n",
    "dataset: mnist\n",
    "model: mlp\n",
    "dataroot: data/MNIST\n",
    "resume from standard_model_for_pilot.pt in checkpoints folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3\n",
      "[Logging in mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_training]\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Number of Classes: 10\n",
      "State OrderedDict([('layers.0.weight', tensor([[-0.0832, -0.0317,  0.0080,  ...,  0.0650, -0.0346, -0.0338],\n",
      "        [-0.0027, -0.0888, -0.0519,  ..., -0.0379,  0.0615,  0.0149],\n",
      "        [-0.1416, -0.0336,  0.0156,  ...,  0.0427,  0.0694,  0.0308],\n",
      "        ...,\n",
      "        [-0.0182, -0.0285,  0.0117,  ...,  0.0094, -0.0225, -0.0526],\n",
      "        [-0.0159,  0.0288, -0.0066,  ...,  0.0381,  0.0633,  0.0451],\n",
      "        [ 0.0131, -0.0608,  0.0516,  ..., -0.0093,  0.0415, -0.0130]])), ('layers.0.bias', tensor([ 0.2570,  0.5360, -0.9828, -0.2736, -0.2282,  0.3082,  0.4359, -0.1057,\n",
      "        -0.0857,  0.2738,  0.0112, -0.4476,  0.2455,  0.2458, -0.0411, -0.3458,\n",
      "        -0.4463,  0.1637, -0.5212,  0.0843,  0.1513, -0.1780, -0.6362,  0.2063,\n",
      "         0.4134,  0.2404, -0.3497, -0.2096, -0.0949, -0.2470,  0.0197,  0.4874])), ('layers.2.weight', tensor([[-0.3519, -0.2154, -0.3365, -0.1412,  0.4156,  0.1818,  0.0200, -0.0604,\n",
      "          0.2205,  0.2322, -0.0053, -0.1393, -0.2035, -0.0579,  0.0095, -0.1644,\n",
      "          0.2235,  0.3024,  0.2238, -0.7361,  0.2985,  0.1393,  0.1623, -0.0921,\n",
      "         -0.0720, -0.1394,  0.2537, -0.1786,  0.1402, -0.0607,  0.0045,  0.0832],\n",
      "        [ 0.3928, -0.1737, -0.1759, -0.4551,  0.2481, -0.4473, -0.0411, -0.2373,\n",
      "         -0.0809,  0.0645,  0.0849,  0.2062, -0.1421, -0.0616,  0.1801, -0.0840,\n",
      "         -0.2335, -0.0692,  0.1498, -0.0470, -0.1586, -0.1081,  0.0933, -0.2024,\n",
      "         -0.1436, -0.1707, -0.0688, -0.5912,  0.1219, -0.1256,  0.2843, -0.1910],\n",
      "        [ 0.4523, -0.3588,  0.0086,  0.0764,  0.1664,  0.4396,  0.0665,  0.4759,\n",
      "         -0.1288, -0.1356, -0.1838,  0.0269, -0.1764, -0.1239,  0.3496, -0.3435,\n",
      "          0.2170, -0.0702,  0.2358,  0.0587, -0.4519, -0.0437,  0.2893, -0.2968,\n",
      "          0.0510,  0.1216,  0.3035,  0.1648, -0.0432,  0.4584,  0.1138, -0.1609],\n",
      "        [-0.2260, -0.0343, -0.1534, -0.0083, -0.2569,  0.0590,  0.2407,  0.2322,\n",
      "         -0.0340,  0.2132,  0.1880,  0.2921, -0.0644, -0.0330,  0.4186,  0.4952,\n",
      "          0.0323,  0.1553, -0.1318, -0.1697,  0.2046, -0.2184,  0.0321, -0.3517,\n",
      "          0.3038, -0.0949, -0.1500,  0.1053, -0.0209, -0.1221, -0.1718, -0.0792],\n",
      "        [ 0.3664,  0.1804, -0.0120,  0.2229, -0.2088,  0.1287, -0.2451, -0.3353,\n",
      "          0.0897, -0.2442,  0.0131, -0.2590, -0.1019,  0.1473,  0.3632,  0.2329,\n",
      "          0.5305,  0.1337, -0.1440,  0.1620,  0.3382, -0.3171,  0.0806,  0.1881,\n",
      "          0.0109,  0.5281, -0.3445,  0.2525, -0.2200, -0.4710,  0.2022, -0.2743],\n",
      "        [ 0.1823, -0.0562, -0.2757, -0.0546, -0.1238, -0.1061,  0.0172, -0.0347,\n",
      "          0.4565,  0.1192, -0.0601,  0.2493, -0.2201,  0.0361,  0.0090,  0.2869,\n",
      "          0.0090, -0.2832, -0.0779, -0.2768, -0.3961, -0.1289,  0.1251, -0.0015,\n",
      "          0.2930,  0.1101,  0.0197,  0.2491,  0.0698,  0.3177,  0.0416,  0.0137],\n",
      "        [-0.3832,  0.2309, -0.1809,  0.1982,  0.0751,  0.0873, -0.1564,  0.0144,\n",
      "         -0.0449, -0.3521,  0.0023, -0.1973, -0.3833,  0.2016, -0.5147, -0.0191,\n",
      "          0.0122, -0.0809,  0.0038,  0.1643,  0.2994,  0.0281, -0.0899, -0.0444,\n",
      "          0.2220,  0.0072, -0.0604, -0.2090, -0.1963, -0.1330, -0.2076,  0.0046],\n",
      "        [-0.2165, -0.1100,  0.0688, -0.3747,  0.4035, -0.0398, -0.0595, -0.1467,\n",
      "         -0.0216,  0.1590, -0.0791, -0.5878,  0.2140,  0.0116,  0.0842,  0.0181,\n",
      "         -0.2411,  0.1744, -0.0815,  0.3069, -0.1610,  0.1093,  0.1149, -0.2111,\n",
      "         -0.4566, -0.0443,  0.1989, -0.1942, -0.2622, -0.1263,  0.3670, -0.2812],\n",
      "        [-0.1144,  0.1658, -0.1994,  0.2232, -0.0683,  0.2219,  0.2655,  0.4258,\n",
      "         -0.0326, -0.1462, -0.0584,  0.2980, -0.0663,  0.1896, -0.0486,  0.3528,\n",
      "         -0.2598,  0.0683,  0.2263, -0.3286,  0.0065, -0.0126, -0.1758,  0.2649,\n",
      "         -0.1740,  0.2994, -0.0692, -0.3554,  0.0484, -0.0219, -0.4493,  0.4110],\n",
      "        [ 0.4281, -0.0311, -0.3707,  0.5601, -0.2563, -0.1194, -0.2108, -0.0102,\n",
      "         -0.1516, -0.0340, -0.2634,  0.4547, -0.1523,  0.6067, -0.4058,  0.1322,\n",
      "         -0.3815,  0.2264, -0.0823, -0.2132, -0.0130,  0.1347,  0.1836,  0.1278,\n",
      "         -0.0120, -0.0764, -0.3119, -0.1457,  0.3770, -0.0323, -0.4128, -0.1316]])), ('layers.2.bias', tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746]))])\n",
      "Args checkpoints/standard_model_for_pilot.pt\n",
      "[0] train metrics:{\"loss\": 1.6957053787638154, \"error\": 0.4350262478126823}\n",
      "Learning Rate : 0.001\n",
      "[0] test metrics:{\"loss\": 1.2201567613601685, \"error\": 0.2158}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.62 sec\n",
      "[1] train metrics:{\"loss\": 1.135481510219172, \"error\": 0.18546371135738687}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.55 sec\n",
      "[2] train metrics:{\"loss\": 1.0566367169994382, \"error\": 0.1521956503624698}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.75 sec\n",
      "[3] train metrics:{\"loss\": 1.0370397905877864, \"error\": 0.14057161903174736}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.79 sec\n",
      "[4] train metrics:{\"loss\": 1.0285105837671848, \"error\": 0.13388467627697692}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.61 sec\n",
      "[5] train metrics:{\"loss\": 1.0239834974342739, \"error\": 0.13053078910090826}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.82 sec\n",
      "[6] train metrics:{\"loss\": 1.0214508123054533, \"error\": 0.12780184984584617}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.85 sec\n",
      "[7] train metrics:{\"loss\": 1.0196682121115777, \"error\": 0.1277601866511124}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.99 sec\n",
      "[8] train metrics:{\"loss\": 1.0185629796230855, \"error\": 0.12644779601699857}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.74 sec\n",
      "[9] train metrics:{\"loss\": 1.0178989100958862, \"error\": 0.1261144904591284}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.94 sec\n",
      "[10] train metrics:{\"loss\": 1.0175718008781531, \"error\": 0.12505207899341722}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.1 sec\n",
      "[11] train metrics:{\"loss\": 1.0170587113515286, \"error\": 0.1247812682276477}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.07 sec\n",
      "[12] train metrics:{\"loss\": 1.016697402378289, \"error\": 0.1252187317723523}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.16 sec\n",
      "[13] train metrics:{\"loss\": 1.016376818798848, \"error\": 0.12488542621448212}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.02 sec\n",
      "[14] train metrics:{\"loss\": 1.0164363585892404, \"error\": 0.12386467794350471}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.88 sec\n",
      "[15] train metrics:{\"loss\": 1.0160483885343825, \"error\": 0.12453128905924506}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.95 sec\n",
      "[16] train metrics:{\"loss\": 1.0159531660292926, \"error\": 0.12482293142238148}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.74 sec\n",
      "[17] train metrics:{\"loss\": 1.015965955176559, \"error\": 0.12442713107241063}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.67 sec\n",
      "[18] train metrics:{\"loss\": 1.0159101984856695, \"error\": 0.1240104991250729}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.73 sec\n",
      "[19] train metrics:{\"loss\": 1.0157534404452986, \"error\": 0.12465627864344637}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.74 sec\n",
      "[20] train metrics:{\"loss\": 1.0156692651229822, \"error\": 0.12405216231980669}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.58 sec\n",
      "[21] train metrics:{\"loss\": 1.015744189621657, \"error\": 0.12451045746187818}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.55 sec\n",
      "[22] train metrics:{\"loss\": 1.015743130570143, \"error\": 0.12415632030664112}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.55 sec\n",
      "[23] train metrics:{\"loss\": 1.015751474828047, \"error\": 0.12469794183818016}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.1 sec\n",
      "[24] train metrics:{\"loss\": 1.0157363732977018, \"error\": 0.12426047829347554}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.53 sec\n",
      "[25] train metrics:{\"loss\": 1.0156331737730246, \"error\": 0.12367719356720273}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.93 sec\n",
      "[26] train metrics:{\"loss\": 1.0157239567924565, \"error\": 0.12380218315140405}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.58 sec\n",
      "[27] train metrics:{\"loss\": 1.0156740184009458, \"error\": 0.12392717273560537}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.09 sec\n",
      "[28] train metrics:{\"loss\": 1.0157745137292935, \"error\": 0.12438546787767686}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.91 sec\n",
      "[29] train metrics:{\"loss\": 1.0156028505246169, \"error\": 0.12455212065661195}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.5 sec\n",
      "[30] train metrics:{\"loss\": 1.015438807938419, \"error\": 0.12313557203566369}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.07 sec\n",
      "Pure training time: 180.01 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset mnist --model mlp --dataroot=data/MNIST/ --filters 1.0 --lr 0.001 \\\n",
    "--resume checkpoints/standard_model_for_pilot.pt --disable-bn \\\n",
    "--weight-decay 0.1 --batch-size 128 --epochs 31 --seed 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Note\n",
    "After running this cell, the code will generate a trace of checkpoints under the \"checkpoints\" folder.\n",
    "They are useful for later cell codes. But you could remove them after completing the experiment.\n",
    "\n",
    "Also, the code would also download a MNIST dataset in the data folder. You could remove it after the\n",
    "experiment.\n",
    "\n",
    "The code also generate a log file under \"logs\" folder if one wants to analyze using matlab. You could\n",
    "remove it after the experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Retain Model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_300_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3\n",
      "[Logging in mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_300_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_training]\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Replacing indexes [ 8526 16694 15152 29352   141 36509 37843 16926 35321 26042 21345  5714\n",
      " 47547 14437 39793 44980 45137  3897 35780 29999 33655 37420 40980 28992\n",
      "   105 40544 41016 46885 46091 40786  5543  7014 20505 25936 16792  2457\n",
      "  1600 13007  7760 15774 46362 33702 32877  2543 33599 32886 35244 29239\n",
      "  8640 23665 45315  3038 22738  3554  4458 36789 11462  2191 23706 10872\n",
      "  9290 32216 25081 12968 28129 20523  5261 16762 26382 19263 12728 37875\n",
      " 36911  7326 21202 31998 26810 28700 36488 42838  3180 24261 25761 13600\n",
      " 18425 29148 39305  4254  2025  4307 45980 28150 36331  8747 35060 28517\n",
      "  8694 12015 38188 36605 26116 12256 18607 11847  1442 19196 18989 33194\n",
      " 26487  5803   828 40152 11342 43196 20715 41802 14043  8865 20144 41373\n",
      " 47285  8202 21858  1815 22335  2739 16404  6882  9838 14297  4773 29745\n",
      "  8784 20420  9033 18865 39460 23585 14421 25902 31362 17568 47282 10213\n",
      " 10851 27398  9097 13317  3946 12763 22347 26179 27559 12416 12204 19720\n",
      " 28625 43760   991 18748  3274 11284 33410 22005  3957 23606 30636 39992\n",
      "  1264 25266 17560 31423 46872  6399  8159 35119  1818 44722 35781 44342\n",
      " 25267   634 46251  4819 19794 29351 33480 27853 45953 19391  8342 23363\n",
      " 10898 22639 11929 33139 20729 23386 14207 42742  6533 15472 42530 19571\n",
      " 22377 37233 37954 28603  5153 40736 28158 13824 24596 47089  4148 32854\n",
      " 44602 27694 42719 24075  6046 21712  7058  1106 33206 27058 40874 12132\n",
      " 27016 21465 25892  8743  8810 33435 33167 23515 47454 24149 46878 44043\n",
      " 12757 41548 24280 38149  3902 38656 29473  9135 19714 31691 38719 42099\n",
      " 41461  6753 39036 38931 19219 20760  6409 44396  3192 30070 21387 10447\n",
      " 47641  5579 43237 20422 15418 29575 24229 42701  5380  5442 12690 44635\n",
      " 35380 24691 28596 36012 38802  8417 18947 17449 14339 25511  4570 22447\n",
      " 12060 46231 41953 29310 37274 10157  1795 18569 36490 23796 29340 43197]\n",
      "Number of Classes: 10\n",
      "State OrderedDict([('layers.0.weight', tensor([[-0.0832, -0.0317,  0.0080,  ...,  0.0650, -0.0346, -0.0338],\n",
      "        [-0.0027, -0.0888, -0.0519,  ..., -0.0379,  0.0615,  0.0149],\n",
      "        [-0.1416, -0.0336,  0.0156,  ...,  0.0427,  0.0694,  0.0308],\n",
      "        ...,\n",
      "        [-0.0182, -0.0285,  0.0117,  ...,  0.0094, -0.0225, -0.0526],\n",
      "        [-0.0159,  0.0288, -0.0066,  ...,  0.0381,  0.0633,  0.0451],\n",
      "        [ 0.0131, -0.0608,  0.0516,  ..., -0.0093,  0.0415, -0.0130]])), ('layers.0.bias', tensor([ 0.2570,  0.5360, -0.9828, -0.2736, -0.2282,  0.3082,  0.4359, -0.1057,\n",
      "        -0.0857,  0.2738,  0.0112, -0.4476,  0.2455,  0.2458, -0.0411, -0.3458,\n",
      "        -0.4463,  0.1637, -0.5212,  0.0843,  0.1513, -0.1780, -0.6362,  0.2063,\n",
      "         0.4134,  0.2404, -0.3497, -0.2096, -0.0949, -0.2470,  0.0197,  0.4874])), ('layers.2.weight', tensor([[-0.3519, -0.2154, -0.3365, -0.1412,  0.4156,  0.1818,  0.0200, -0.0604,\n",
      "          0.2205,  0.2322, -0.0053, -0.1393, -0.2035, -0.0579,  0.0095, -0.1644,\n",
      "          0.2235,  0.3024,  0.2238, -0.7361,  0.2985,  0.1393,  0.1623, -0.0921,\n",
      "         -0.0720, -0.1394,  0.2537, -0.1786,  0.1402, -0.0607,  0.0045,  0.0832],\n",
      "        [ 0.3928, -0.1737, -0.1759, -0.4551,  0.2481, -0.4473, -0.0411, -0.2373,\n",
      "         -0.0809,  0.0645,  0.0849,  0.2062, -0.1421, -0.0616,  0.1801, -0.0840,\n",
      "         -0.2335, -0.0692,  0.1498, -0.0470, -0.1586, -0.1081,  0.0933, -0.2024,\n",
      "         -0.1436, -0.1707, -0.0688, -0.5912,  0.1219, -0.1256,  0.2843, -0.1910],\n",
      "        [ 0.4523, -0.3588,  0.0086,  0.0764,  0.1664,  0.4396,  0.0665,  0.4759,\n",
      "         -0.1288, -0.1356, -0.1838,  0.0269, -0.1764, -0.1239,  0.3496, -0.3435,\n",
      "          0.2170, -0.0702,  0.2358,  0.0587, -0.4519, -0.0437,  0.2893, -0.2968,\n",
      "          0.0510,  0.1216,  0.3035,  0.1648, -0.0432,  0.4584,  0.1138, -0.1609],\n",
      "        [-0.2260, -0.0343, -0.1534, -0.0083, -0.2569,  0.0590,  0.2407,  0.2322,\n",
      "         -0.0340,  0.2132,  0.1880,  0.2921, -0.0644, -0.0330,  0.4186,  0.4952,\n",
      "          0.0323,  0.1553, -0.1318, -0.1697,  0.2046, -0.2184,  0.0321, -0.3517,\n",
      "          0.3038, -0.0949, -0.1500,  0.1053, -0.0209, -0.1221, -0.1718, -0.0792],\n",
      "        [ 0.3664,  0.1804, -0.0120,  0.2229, -0.2088,  0.1287, -0.2451, -0.3353,\n",
      "          0.0897, -0.2442,  0.0131, -0.2590, -0.1019,  0.1473,  0.3632,  0.2329,\n",
      "          0.5305,  0.1337, -0.1440,  0.1620,  0.3382, -0.3171,  0.0806,  0.1881,\n",
      "          0.0109,  0.5281, -0.3445,  0.2525, -0.2200, -0.4710,  0.2022, -0.2743],\n",
      "        [ 0.1823, -0.0562, -0.2757, -0.0546, -0.1238, -0.1061,  0.0172, -0.0347,\n",
      "          0.4565,  0.1192, -0.0601,  0.2493, -0.2201,  0.0361,  0.0090,  0.2869,\n",
      "          0.0090, -0.2832, -0.0779, -0.2768, -0.3961, -0.1289,  0.1251, -0.0015,\n",
      "          0.2930,  0.1101,  0.0197,  0.2491,  0.0698,  0.3177,  0.0416,  0.0137],\n",
      "        [-0.3832,  0.2309, -0.1809,  0.1982,  0.0751,  0.0873, -0.1564,  0.0144,\n",
      "         -0.0449, -0.3521,  0.0023, -0.1973, -0.3833,  0.2016, -0.5147, -0.0191,\n",
      "          0.0122, -0.0809,  0.0038,  0.1643,  0.2994,  0.0281, -0.0899, -0.0444,\n",
      "          0.2220,  0.0072, -0.0604, -0.2090, -0.1963, -0.1330, -0.2076,  0.0046],\n",
      "        [-0.2165, -0.1100,  0.0688, -0.3747,  0.4035, -0.0398, -0.0595, -0.1467,\n",
      "         -0.0216,  0.1590, -0.0791, -0.5878,  0.2140,  0.0116,  0.0842,  0.0181,\n",
      "         -0.2411,  0.1744, -0.0815,  0.3069, -0.1610,  0.1093,  0.1149, -0.2111,\n",
      "         -0.4566, -0.0443,  0.1989, -0.1942, -0.2622, -0.1263,  0.3670, -0.2812],\n",
      "        [-0.1144,  0.1658, -0.1994,  0.2232, -0.0683,  0.2219,  0.2655,  0.4258,\n",
      "         -0.0326, -0.1462, -0.0584,  0.2980, -0.0663,  0.1896, -0.0486,  0.3528,\n",
      "         -0.2598,  0.0683,  0.2263, -0.3286,  0.0065, -0.0126, -0.1758,  0.2649,\n",
      "         -0.1740,  0.2994, -0.0692, -0.3554,  0.0484, -0.0219, -0.4493,  0.4110],\n",
      "        [ 0.4281, -0.0311, -0.3707,  0.5601, -0.2563, -0.1194, -0.2108, -0.0102,\n",
      "         -0.1516, -0.0340, -0.2634,  0.4547, -0.1523,  0.6067, -0.4058,  0.1322,\n",
      "         -0.3815,  0.2264, -0.0823, -0.2132, -0.0130,  0.1347,  0.1836,  0.1278,\n",
      "         -0.0120, -0.0764, -0.3119, -0.1457,  0.3770, -0.0323, -0.4128, -0.1316]])), ('layers.2.bias', tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746]))])\n",
      "Args checkpoints/standard_model_for_pilot.pt\n",
      "[0] train metrics:{\"loss\": 1.6955508042470524, \"error\": 0.4350262478126823}\n",
      "Learning Rate : 0.001\n",
      "[0] test metrics:{\"loss\": 1.220088168334961, \"error\": 0.2163}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.92 sec\n",
      "[1] train metrics:{\"loss\": 1.1354534324730707, \"error\": 0.18535955337055246}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.65 sec\n",
      "[2] train metrics:{\"loss\": 1.056726030901704, \"error\": 0.15227897675193733}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.6 sec\n",
      "[3] train metrics:{\"loss\": 1.0371734988102366, \"error\": 0.14057161903174736}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.55 sec\n",
      "[4] train metrics:{\"loss\": 1.028648248931466, \"error\": 0.13371802349804182}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.72 sec\n",
      "[5] train metrics:{\"loss\": 1.024162956063285, \"error\": 0.13086409465877843}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.01 sec\n",
      "[6] train metrics:{\"loss\": 1.0216317594711923, \"error\": 0.12803099741688193}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.69 sec\n",
      "[7] train metrics:{\"loss\": 1.0198602803487915, \"error\": 0.1279476710274144}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.87 sec\n",
      "[8] train metrics:{\"loss\": 1.0187525477630677, \"error\": 0.12640613282226482}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.79 sec\n",
      "[9] train metrics:{\"loss\": 1.0180947887193221, \"error\": 0.12623948004332972}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.8 sec\n",
      "[10] train metrics:{\"loss\": 1.0177762444918677, \"error\": 0.12536455295392052}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.48 sec\n",
      "[11] train metrics:{\"loss\": 1.017264149882537, \"error\": 0.12498958420131656}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.06 sec\n",
      "[12] train metrics:{\"loss\": 1.016896297669234, \"error\": 0.1252187317723523}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.06 sec\n",
      "[13] train metrics:{\"loss\": 1.0165873311497888, \"error\": 0.1253437213565536}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.15 sec\n",
      "[14] train metrics:{\"loss\": 1.0166354835376115, \"error\": 0.12396883593033914}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.72 sec\n",
      "[15] train metrics:{\"loss\": 1.0162662003658363, \"error\": 0.12498958420131656}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.75 sec\n",
      "[16] train metrics:{\"loss\": 1.0161743731997765, \"error\": 0.12490625781184901}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.02 sec\n",
      "[17] train metrics:{\"loss\": 1.0162088719817681, \"error\": 0.12465627864344637}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.81 sec\n",
      "[18] train metrics:{\"loss\": 1.016125079642017, \"error\": 0.12413548870927422}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.97 sec\n",
      "[19] train metrics:{\"loss\": 1.0159665824681379, \"error\": 0.12457295225397884}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.57 sec\n",
      "[20] train metrics:{\"loss\": 1.0158672984883483, \"error\": 0.12428130989084243}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.58 sec\n",
      "[21] train metrics:{\"loss\": 1.0159629398599763, \"error\": 0.12455212065661195}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.7 sec\n",
      "[22] train metrics:{\"loss\": 1.0159606663110543, \"error\": 0.12409382551454046}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.54 sec\n",
      "[23] train metrics:{\"loss\": 1.0159797972316056, \"error\": 0.12498958420131656}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.68 sec\n",
      "[24] train metrics:{\"loss\": 1.0159649011910175, \"error\": 0.12407299391717357}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.06 sec\n",
      "[25] train metrics:{\"loss\": 1.015828314502779, \"error\": 0.12384384634613782}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.54 sec\n",
      "[26] train metrics:{\"loss\": 1.0159221884906515, \"error\": 0.12384384634613782}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.64 sec\n",
      "[27] train metrics:{\"loss\": 1.0158880807669817, \"error\": 0.12388550954087159}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.61 sec\n",
      "[28] train metrics:{\"loss\": 1.0159736355884146, \"error\": 0.12469794183818016}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.61 sec\n",
      "[29] train metrics:{\"loss\": 1.0158080630834456, \"error\": 0.12457295225397884}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.87 sec\n",
      "[30] train metrics:{\"loss\": 1.0156555478547615, \"error\": 0.12323973002249812}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.91 sec\n",
      "Pure training time: 179.79000000000002 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset mnist --model mlp --dataroot=data/MNIST/ --filters 1.0 --lr 0.001 \\\n",
    "--resume checkpoints/standard_model_for_pilot.pt --disable-bn \\\n",
    "--weight-decay 0.1 --batch-size 128 --epochs 31 \\\n",
    "--forget-class 0,1,2,3,4,5 --num-to-forget 300 --seed 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
