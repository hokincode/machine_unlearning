{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/2gycpkq57p97cpwvmwvm69m00000gn/T/ipykernel_11651/1595774001.py:24: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import variational\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from itertools import cycle\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from typing import List\n",
    "import itertools\n",
    "from tqdm.autonotebook import tqdm\n",
    "from models import *\n",
    "import models\n",
    "from logger import *\n",
    "import wandb\n",
    "\n",
    "from thirdparty.repdistiller.helper.util import adjust_learning_rate as sgda_adjust_learning_rate\n",
    "from thirdparty.repdistiller.distiller_zoo import DistillKL, HintLoss, Attention, Similarity, Correlation, VIDLoss, RKDLoss\n",
    "from thirdparty.repdistiller.distiller_zoo import PKT, ABLoss, FactorTransfer, KDSVD, FSP, NSTLoss\n",
    "\n",
    "from thirdparty.repdistiller.helper.loops import train_distill, train_distill_hide, train_distill_linear, train_vanilla, train_negrad, train_bcu, train_bcu_distill, validate\n",
    "from thirdparty.repdistiller.helper.pretrain import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb():\n",
    "    import pdb\n",
    "    pdb.set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_count(model):\n",
    "    count=0\n",
    "    for p in model.parameters():\n",
    "        count+=np.prod(np.array(list(p.shape)))\n",
    "    print(f'Total Number of Parameters: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_params(model):\n",
    "    param = []\n",
    "    for p in model.parameters():\n",
    "        param.append(p.data.view(-1).cpu().numpy())\n",
    "    return np.concatenate(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param_shape(model):\n",
    "    for k,p in model.named_parameters():\n",
    "        print(k,p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: small_mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3\n",
      "[Logging in small_mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_training]\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/small_mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 18143788.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/small_mnist/MNIST/raw/train-images-idx3-ubyte.gz to data/small_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/small_mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 43032218.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/small_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to data/small_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/small_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 8139991.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/small_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to data/small_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/small_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5822288.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/small_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/small_mnist/MNIST/raw\n",
      "\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Number of Classes: 10\n",
      "State OrderedDict([('layers.0.weight', tensor([[-0.0832, -0.0317,  0.0080,  ...,  0.0650, -0.0346, -0.0338],\n",
      "        [-0.0027, -0.0888, -0.0519,  ..., -0.0379,  0.0615,  0.0149],\n",
      "        [-0.1416, -0.0336,  0.0156,  ...,  0.0427,  0.0694,  0.0308],\n",
      "        ...,\n",
      "        [-0.0182, -0.0285,  0.0117,  ...,  0.0094, -0.0225, -0.0526],\n",
      "        [-0.0159,  0.0288, -0.0066,  ...,  0.0381,  0.0633,  0.0451],\n",
      "        [ 0.0131, -0.0608,  0.0516,  ..., -0.0093,  0.0415, -0.0130]])), ('layers.0.bias', tensor([ 0.2570,  0.5360, -0.9828, -0.2736, -0.2282,  0.3082,  0.4359, -0.1057,\n",
      "        -0.0857,  0.2738,  0.0112, -0.4476,  0.2455,  0.2458, -0.0411, -0.3458,\n",
      "        -0.4463,  0.1637, -0.5212,  0.0843,  0.1513, -0.1780, -0.6362,  0.2063,\n",
      "         0.4134,  0.2404, -0.3497, -0.2096, -0.0949, -0.2470,  0.0197,  0.4874])), ('layers.2.weight', tensor([[-0.3519, -0.2154, -0.3365, -0.1412,  0.4156,  0.1818,  0.0200, -0.0604,\n",
      "          0.2205,  0.2322, -0.0053, -0.1393, -0.2035, -0.0579,  0.0095, -0.1644,\n",
      "          0.2235,  0.3024,  0.2238, -0.7361,  0.2985,  0.1393,  0.1623, -0.0921,\n",
      "         -0.0720, -0.1394,  0.2537, -0.1786,  0.1402, -0.0607,  0.0045,  0.0832],\n",
      "        [ 0.3928, -0.1737, -0.1759, -0.4551,  0.2481, -0.4473, -0.0411, -0.2373,\n",
      "         -0.0809,  0.0645,  0.0849,  0.2062, -0.1421, -0.0616,  0.1801, -0.0840,\n",
      "         -0.2335, -0.0692,  0.1498, -0.0470, -0.1586, -0.1081,  0.0933, -0.2024,\n",
      "         -0.1436, -0.1707, -0.0688, -0.5912,  0.1219, -0.1256,  0.2843, -0.1910],\n",
      "        [ 0.4523, -0.3588,  0.0086,  0.0764,  0.1664,  0.4396,  0.0665,  0.4759,\n",
      "         -0.1288, -0.1356, -0.1838,  0.0269, -0.1764, -0.1239,  0.3496, -0.3435,\n",
      "          0.2170, -0.0702,  0.2358,  0.0587, -0.4519, -0.0437,  0.2893, -0.2968,\n",
      "          0.0510,  0.1216,  0.3035,  0.1648, -0.0432,  0.4584,  0.1138, -0.1609],\n",
      "        [-0.2260, -0.0343, -0.1534, -0.0083, -0.2569,  0.0590,  0.2407,  0.2322,\n",
      "         -0.0340,  0.2132,  0.1880,  0.2921, -0.0644, -0.0330,  0.4186,  0.4952,\n",
      "          0.0323,  0.1553, -0.1318, -0.1697,  0.2046, -0.2184,  0.0321, -0.3517,\n",
      "          0.3038, -0.0949, -0.1500,  0.1053, -0.0209, -0.1221, -0.1718, -0.0792],\n",
      "        [ 0.3664,  0.1804, -0.0120,  0.2229, -0.2088,  0.1287, -0.2451, -0.3353,\n",
      "          0.0897, -0.2442,  0.0131, -0.2590, -0.1019,  0.1473,  0.3632,  0.2329,\n",
      "          0.5305,  0.1337, -0.1440,  0.1620,  0.3382, -0.3171,  0.0806,  0.1881,\n",
      "          0.0109,  0.5281, -0.3445,  0.2525, -0.2200, -0.4710,  0.2022, -0.2743],\n",
      "        [ 0.1823, -0.0562, -0.2757, -0.0546, -0.1238, -0.1061,  0.0172, -0.0347,\n",
      "          0.4565,  0.1192, -0.0601,  0.2493, -0.2201,  0.0361,  0.0090,  0.2869,\n",
      "          0.0090, -0.2832, -0.0779, -0.2768, -0.3961, -0.1289,  0.1251, -0.0015,\n",
      "          0.2930,  0.1101,  0.0197,  0.2491,  0.0698,  0.3177,  0.0416,  0.0137],\n",
      "        [-0.3832,  0.2309, -0.1809,  0.1982,  0.0751,  0.0873, -0.1564,  0.0144,\n",
      "         -0.0449, -0.3521,  0.0023, -0.1973, -0.3833,  0.2016, -0.5147, -0.0191,\n",
      "          0.0122, -0.0809,  0.0038,  0.1643,  0.2994,  0.0281, -0.0899, -0.0444,\n",
      "          0.2220,  0.0072, -0.0604, -0.2090, -0.1963, -0.1330, -0.2076,  0.0046],\n",
      "        [-0.2165, -0.1100,  0.0688, -0.3747,  0.4035, -0.0398, -0.0595, -0.1467,\n",
      "         -0.0216,  0.1590, -0.0791, -0.5878,  0.2140,  0.0116,  0.0842,  0.0181,\n",
      "         -0.2411,  0.1744, -0.0815,  0.3069, -0.1610,  0.1093,  0.1149, -0.2111,\n",
      "         -0.4566, -0.0443,  0.1989, -0.1942, -0.2622, -0.1263,  0.3670, -0.2812],\n",
      "        [-0.1144,  0.1658, -0.1994,  0.2232, -0.0683,  0.2219,  0.2655,  0.4258,\n",
      "         -0.0326, -0.1462, -0.0584,  0.2980, -0.0663,  0.1896, -0.0486,  0.3528,\n",
      "         -0.2598,  0.0683,  0.2263, -0.3286,  0.0065, -0.0126, -0.1758,  0.2649,\n",
      "         -0.1740,  0.2994, -0.0692, -0.3554,  0.0484, -0.0219, -0.4493,  0.4110],\n",
      "        [ 0.4281, -0.0311, -0.3707,  0.5601, -0.2563, -0.1194, -0.2108, -0.0102,\n",
      "         -0.1516, -0.0340, -0.2634,  0.4547, -0.1523,  0.6067, -0.4058,  0.1322,\n",
      "         -0.3815,  0.2264, -0.0823, -0.2132, -0.0130,  0.1347,  0.1836,  0.1278,\n",
      "         -0.0120, -0.0764, -0.3119, -0.1457,  0.3770, -0.0323, -0.4128, -0.1316]])), ('layers.2.bias', tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746]))])\n",
      "Args checkpoints/small_mnist_standard_model.pt\n",
      "[0] train metrics:{\"loss\": 2.466917371749878, \"error\": 0.88125}\n",
      "Learning Rate : 0.001\n",
      "[0] test metrics:{\"loss\": 2.4780861251831054, \"error\": 0.9136}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 1.45 sec\n",
      "[1] train metrics:{\"loss\": 2.4606986045837402, \"error\": 0.88125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.08 sec\n",
      "[2] train metrics:{\"loss\": 2.4485052108764647, \"error\": 0.88125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[3] train metrics:{\"loss\": 2.4326248168945312, \"error\": 0.88125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[4] train metrics:{\"loss\": 2.4135098457336426, \"error\": 0.88125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[5] train metrics:{\"loss\": 2.3932637691497805, \"error\": 0.8875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[6] train metrics:{\"loss\": 2.373811626434326, \"error\": 0.9125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[7] train metrics:{\"loss\": 2.353605031967163, \"error\": 0.9}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[8] train metrics:{\"loss\": 2.333400821685791, \"error\": 0.8875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[9] train metrics:{\"loss\": 2.3153567790985106, \"error\": 0.8625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[10] train metrics:{\"loss\": 2.298601007461548, \"error\": 0.8625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[11] train metrics:{\"loss\": 2.2807053089141847, \"error\": 0.8375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[12] train metrics:{\"loss\": 2.265712928771973, \"error\": 0.8375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[13] train metrics:{\"loss\": 2.2509040355682375, \"error\": 0.825}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[14] train metrics:{\"loss\": 2.236454486846924, \"error\": 0.81875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[15] train metrics:{\"loss\": 2.223023700714111, \"error\": 0.8125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[16] train metrics:{\"loss\": 2.2097388744354247, \"error\": 0.8125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[17] train metrics:{\"loss\": 2.1972795009613035, \"error\": 0.8}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[18] train metrics:{\"loss\": 2.1845449447631835, \"error\": 0.7875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[19] train metrics:{\"loss\": 2.1726517200469972, \"error\": 0.76875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[20] train metrics:{\"loss\": 2.1612650394439696, \"error\": 0.75}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[21] train metrics:{\"loss\": 2.148988962173462, \"error\": 0.71875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[22] train metrics:{\"loss\": 2.1371514797210693, \"error\": 0.7125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[23] train metrics:{\"loss\": 2.125600004196167, \"error\": 0.69375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[24] train metrics:{\"loss\": 2.1137460231781007, \"error\": 0.6875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[25] train metrics:{\"loss\": 2.102158212661743, \"error\": 0.66875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[26] train metrics:{\"loss\": 2.0903937578201295, \"error\": 0.65625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[27] train metrics:{\"loss\": 2.0788363456726073, \"error\": 0.6375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[28] train metrics:{\"loss\": 2.066655731201172, \"error\": 0.625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[29] train metrics:{\"loss\": 2.0546496391296385, \"error\": 0.6125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[30] train metrics:{\"loss\": 2.0425718307495115, \"error\": 0.6}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "Pure training time: 0.7600000000000005 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset small_mnist --model mlp --dataroot=data/small_mnist/ --filters 1.0 --lr 0.001 \\\n",
    "--resume checkpoints/small_mnist_standard_model.pt --disable-bn \\\n",
    "--weight-decay 0.1 --batch-size 128 --epochs 31 --seed 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: small_mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_48_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3\n",
      "[Logging in small_mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_48_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_training]\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Replacing indexes [36 28 54 23 16 80  2 25 84 13 59 88 76 14  0 21  3 27 74 71 11 81 30 29\n",
      "  5 73 56 95 83  1 18 24 44 35 60  6 48 87 10 12 85 65 91 32 19 62 93 53]\n",
      "Number of Classes: 10\n",
      "State OrderedDict([('layers.0.weight', tensor([[-0.0832, -0.0317,  0.0080,  ...,  0.0650, -0.0346, -0.0338],\n",
      "        [-0.0027, -0.0888, -0.0519,  ..., -0.0379,  0.0615,  0.0149],\n",
      "        [-0.1416, -0.0336,  0.0156,  ...,  0.0427,  0.0694,  0.0308],\n",
      "        ...,\n",
      "        [-0.0182, -0.0285,  0.0117,  ...,  0.0094, -0.0225, -0.0526],\n",
      "        [-0.0159,  0.0288, -0.0066,  ...,  0.0381,  0.0633,  0.0451],\n",
      "        [ 0.0131, -0.0608,  0.0516,  ..., -0.0093,  0.0415, -0.0130]])), ('layers.0.bias', tensor([ 0.2570,  0.5360, -0.9828, -0.2736, -0.2282,  0.3082,  0.4359, -0.1057,\n",
      "        -0.0857,  0.2738,  0.0112, -0.4476,  0.2455,  0.2458, -0.0411, -0.3458,\n",
      "        -0.4463,  0.1637, -0.5212,  0.0843,  0.1513, -0.1780, -0.6362,  0.2063,\n",
      "         0.4134,  0.2404, -0.3497, -0.2096, -0.0949, -0.2470,  0.0197,  0.4874])), ('layers.2.weight', tensor([[-0.3519, -0.2154, -0.3365, -0.1412,  0.4156,  0.1818,  0.0200, -0.0604,\n",
      "          0.2205,  0.2322, -0.0053, -0.1393, -0.2035, -0.0579,  0.0095, -0.1644,\n",
      "          0.2235,  0.3024,  0.2238, -0.7361,  0.2985,  0.1393,  0.1623, -0.0921,\n",
      "         -0.0720, -0.1394,  0.2537, -0.1786,  0.1402, -0.0607,  0.0045,  0.0832],\n",
      "        [ 0.3928, -0.1737, -0.1759, -0.4551,  0.2481, -0.4473, -0.0411, -0.2373,\n",
      "         -0.0809,  0.0645,  0.0849,  0.2062, -0.1421, -0.0616,  0.1801, -0.0840,\n",
      "         -0.2335, -0.0692,  0.1498, -0.0470, -0.1586, -0.1081,  0.0933, -0.2024,\n",
      "         -0.1436, -0.1707, -0.0688, -0.5912,  0.1219, -0.1256,  0.2843, -0.1910],\n",
      "        [ 0.4523, -0.3588,  0.0086,  0.0764,  0.1664,  0.4396,  0.0665,  0.4759,\n",
      "         -0.1288, -0.1356, -0.1838,  0.0269, -0.1764, -0.1239,  0.3496, -0.3435,\n",
      "          0.2170, -0.0702,  0.2358,  0.0587, -0.4519, -0.0437,  0.2893, -0.2968,\n",
      "          0.0510,  0.1216,  0.3035,  0.1648, -0.0432,  0.4584,  0.1138, -0.1609],\n",
      "        [-0.2260, -0.0343, -0.1534, -0.0083, -0.2569,  0.0590,  0.2407,  0.2322,\n",
      "         -0.0340,  0.2132,  0.1880,  0.2921, -0.0644, -0.0330,  0.4186,  0.4952,\n",
      "          0.0323,  0.1553, -0.1318, -0.1697,  0.2046, -0.2184,  0.0321, -0.3517,\n",
      "          0.3038, -0.0949, -0.1500,  0.1053, -0.0209, -0.1221, -0.1718, -0.0792],\n",
      "        [ 0.3664,  0.1804, -0.0120,  0.2229, -0.2088,  0.1287, -0.2451, -0.3353,\n",
      "          0.0897, -0.2442,  0.0131, -0.2590, -0.1019,  0.1473,  0.3632,  0.2329,\n",
      "          0.5305,  0.1337, -0.1440,  0.1620,  0.3382, -0.3171,  0.0806,  0.1881,\n",
      "          0.0109,  0.5281, -0.3445,  0.2525, -0.2200, -0.4710,  0.2022, -0.2743],\n",
      "        [ 0.1823, -0.0562, -0.2757, -0.0546, -0.1238, -0.1061,  0.0172, -0.0347,\n",
      "          0.4565,  0.1192, -0.0601,  0.2493, -0.2201,  0.0361,  0.0090,  0.2869,\n",
      "          0.0090, -0.2832, -0.0779, -0.2768, -0.3961, -0.1289,  0.1251, -0.0015,\n",
      "          0.2930,  0.1101,  0.0197,  0.2491,  0.0698,  0.3177,  0.0416,  0.0137],\n",
      "        [-0.3832,  0.2309, -0.1809,  0.1982,  0.0751,  0.0873, -0.1564,  0.0144,\n",
      "         -0.0449, -0.3521,  0.0023, -0.1973, -0.3833,  0.2016, -0.5147, -0.0191,\n",
      "          0.0122, -0.0809,  0.0038,  0.1643,  0.2994,  0.0281, -0.0899, -0.0444,\n",
      "          0.2220,  0.0072, -0.0604, -0.2090, -0.1963, -0.1330, -0.2076,  0.0046],\n",
      "        [-0.2165, -0.1100,  0.0688, -0.3747,  0.4035, -0.0398, -0.0595, -0.1467,\n",
      "         -0.0216,  0.1590, -0.0791, -0.5878,  0.2140,  0.0116,  0.0842,  0.0181,\n",
      "         -0.2411,  0.1744, -0.0815,  0.3069, -0.1610,  0.1093,  0.1149, -0.2111,\n",
      "         -0.4566, -0.0443,  0.1989, -0.1942, -0.2622, -0.1263,  0.3670, -0.2812],\n",
      "        [-0.1144,  0.1658, -0.1994,  0.2232, -0.0683,  0.2219,  0.2655,  0.4258,\n",
      "         -0.0326, -0.1462, -0.0584,  0.2980, -0.0663,  0.1896, -0.0486,  0.3528,\n",
      "         -0.2598,  0.0683,  0.2263, -0.3286,  0.0065, -0.0126, -0.1758,  0.2649,\n",
      "         -0.1740,  0.2994, -0.0692, -0.3554,  0.0484, -0.0219, -0.4493,  0.4110],\n",
      "        [ 0.4281, -0.0311, -0.3707,  0.5601, -0.2563, -0.1194, -0.2108, -0.0102,\n",
      "         -0.1516, -0.0340, -0.2634,  0.4547, -0.1523,  0.6067, -0.4058,  0.1322,\n",
      "         -0.3815,  0.2264, -0.0823, -0.2132, -0.0130,  0.1347,  0.1836,  0.1278,\n",
      "         -0.0120, -0.0764, -0.3119, -0.1457,  0.3770, -0.0323, -0.4128, -0.1316]])), ('layers.2.bias', tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746]))])\n",
      "Args checkpoints/small_mnist_standard_model.pt\n",
      "[0] train metrics:{\"loss\": 2.5104956150054933, \"error\": 0.85}\n",
      "Learning Rate : 0.001\n",
      "[0] test metrics:{\"loss\": 2.4783990886688234, \"error\": 0.9134}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 1.24 sec\n",
      "[1] train metrics:{\"loss\": 2.5018311977386474, \"error\": 0.85}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[2] train metrics:{\"loss\": 2.4848845481872557, \"error\": 0.85}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[3] train metrics:{\"loss\": 2.4625959396362305, \"error\": 0.85}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[4] train metrics:{\"loss\": 2.435410499572754, \"error\": 0.85625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[5] train metrics:{\"loss\": 2.4081695079803467, \"error\": 0.85625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[6] train metrics:{\"loss\": 2.380506896972656, \"error\": 0.8375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.04 sec\n",
      "[7] train metrics:{\"loss\": 2.352062797546387, \"error\": 0.83125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[8] train metrics:{\"loss\": 2.3250678539276124, \"error\": 0.85}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[9] train metrics:{\"loss\": 2.299799680709839, \"error\": 0.85625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[10] train metrics:{\"loss\": 2.2763756275177003, \"error\": 0.825}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[11] train metrics:{\"loss\": 2.2519399166107177, \"error\": 0.825}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[12] train metrics:{\"loss\": 2.2290186405181887, \"error\": 0.78125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[13] train metrics:{\"loss\": 2.2058980464935303, \"error\": 0.76875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[14] train metrics:{\"loss\": 2.1828660488128664, \"error\": 0.74375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[15] train metrics:{\"loss\": 2.159789228439331, \"error\": 0.71875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[16] train metrics:{\"loss\": 2.138278770446777, \"error\": 0.71875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[17] train metrics:{\"loss\": 2.118451452255249, \"error\": 0.73125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[18] train metrics:{\"loss\": 2.0970787048339843, \"error\": 0.70625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[19] train metrics:{\"loss\": 2.077108955383301, \"error\": 0.6875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[20] train metrics:{\"loss\": 2.057694339752197, \"error\": 0.66875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[21] train metrics:{\"loss\": 2.0378445625305175, \"error\": 0.6625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[22] train metrics:{\"loss\": 2.0184820652008058, \"error\": 0.6625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[23] train metrics:{\"loss\": 1.9997740983963013, \"error\": 0.6375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[24] train metrics:{\"loss\": 1.9812719821929932, \"error\": 0.6375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[25] train metrics:{\"loss\": 1.963568115234375, \"error\": 0.6375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[26] train metrics:{\"loss\": 1.9455500841140747, \"error\": 0.625}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[27] train metrics:{\"loss\": 1.927706527709961, \"error\": 0.61875}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "[28] train metrics:{\"loss\": 1.9104714393615723, \"error\": 0.59375}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[29] train metrics:{\"loss\": 1.8932575225830077, \"error\": 0.58125}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.02 sec\n",
      "[30] train metrics:{\"loss\": 1.8759487867355347, \"error\": 0.575}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 0.03 sec\n",
      "Pure training time: 0.6700000000000004 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset small_mnist --model mlp --dataroot=data/small_mnist/ --filters 1.0 --lr 0.001 \\\n",
    "--resume checkpoints/small_mnist_standard_model.pt --disable-bn \\\n",
    "--weight-decay 0.1 --batch-size 128 --epochs 31 \\\n",
    "--forget-class 0,1,2,3,4,5 --num-to-forget 48 --seed 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict={}\n",
    "training_epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict['epoch']=training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters: 33130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameter_count(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "model0 = copy.deepcopy(model)\n",
    "model_initial = copy.deepcopy(model)\n",
    "\n",
    "arch = args.model \n",
    "filters=args.filters\n",
    "arch_filters = arch +'_'+ str(filters).replace('.','_')\n",
    "augment = False\n",
    "dataset = args.dataset\n",
    "class_to_forget = args.forget_class\n",
    "init_checkpoint = f\"checkpoints/{args.name}_init.pt\"\n",
    "num_classes=args.num_classes\n",
    "num_to_forget = args.num_to_forget\n",
    "num_total = len(train_loader.dataset)\n",
    "num_to_retain = num_total - 300#num_to_forget\n",
    "seed = args.seed\n",
    "unfreeze_start = None\n",
    "\n",
    "learningrate=f\"lr_{str(args.lr).replace('.','_')}\"\n",
    "batch_size=f\"_bs_{str(args.batch_size)}\"\n",
    "lossfn=f\"_ls_{args.lossfn}\"\n",
    "wd=f\"_wd_{str(args.weight_decay).replace('.','_')}\"\n",
    "seed_name=f\"_seed_{args.seed}_\"\n",
    "\n",
    "num_tag = '' if num_to_forget is None else f'_num_{num_to_forget}'\n",
    "unfreeze_tag = '_' if unfreeze_start is None else f'_unfreeze_from_{unfreeze_start}_'\n",
    "augment_tag = '' if not augment else f'augment_'\n",
    "\n",
    "m_name = f'checkpoints/{dataset}_{arch_filters}_forget_None{unfreeze_tag}{augment_tag}{learningrate}{batch_size}{lossfn}{wd}{seed_name}{training_epochs}.pt'\n",
    "m0_name = f'checkpoints/{dataset}_{arch_filters}_forget_{class_to_forget}{num_tag}{unfreeze_tag}{augment_tag}{learningrate}{batch_size}{lossfn}{wd}{seed_name}{training_epochs}.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(m_name))\n",
    "model0.load_state_dict(torch.load(m0_name))\n",
    "model_initial.load_state_dict(torch.load(init_checkpoint))\n",
    "\n",
    "teacher = copy.deepcopy(model)\n",
    "student = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.data0 = p.data.clone()\n",
    "for p in model0.parameters():\n",
    "    p.data0 = p.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict['args']=args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between w(D) and w(D_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(model,model0):\n",
    "    distance=0\n",
    "    normalization=0\n",
    "    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n",
    "        space='  ' if 'bias' in k else ''\n",
    "        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n",
    "        current_norm=p.data0.pow(2).sum().item()\n",
    "        distance+=current_dist\n",
    "        normalization+=current_norm\n",
    "    print(f'Distance: {np.sqrt(distance)}')\n",
    "    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n",
    "    return 1.0*np.sqrt(distance/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.32597514247070725\n",
      "Normalized Distance: 0.0349803333470057\n"
     ]
    }
   ],
   "source": [
    "log_dict['dist_Original_Retrain']=distance(model,model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance of w(D) from initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ntk_init(resume,seed=1):\n",
    "    manual_seed(seed)\n",
    "    model_init = models.get_model(arch, num_classes=num_classes, filters_percentage=filters).to(args.device)\n",
    "    model_init.load_state_dict(torch.load(resume))\n",
    "    return model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = ntk_init(init_checkpoint,args.seed)\n",
    "for p in model_init.parameters():\n",
    "    p.data0 = p.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.45774434608354925\n",
      "Normalized Distance: 0.04913588162373315\n"
     ]
    }
   ],
   "source": [
    "log_dict['dist_Original_Original_init']=distance(model_init,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.retain_bs = 32\n",
    "args.forget_bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confuse mode: False\n",
      "split mode: train\n",
      "confuse mode: False\n",
      "split mode: train\n",
      "Replacing indexes [36 28 54 23 16 80  2 25 84 13 59 88 76 14  0 21  3 27 74 71 11 81 30 29\n",
      "  5 73 56 95 83  1 18 24 44 35 60  6 48 87 10 12 85 65 91 32 19 62 93 53]\n"
     ]
    }
   ],
   "source": [
    "train_loader_full, valid_loader_full, test_loader_full   = datasets.get_loaders(dataset, batch_size=args.batch_size, seed=seed, root=args.dataroot, augment=False, shuffle=True)\n",
    "marked_loader, _, _ = datasets.get_loaders(dataset, class_to_replace=class_to_forget, num_indexes_to_replace=num_to_forget, only_mark=True, batch_size=1, seed=seed, root=args.dataroot, augment=False, shuffle=True)\n",
    "\n",
    "def replace_loader_dataset(data_loader, dataset, batch_size=args.batch_size, seed=1, shuffle=True):\n",
    "    manual_seed(seed)\n",
    "    loader_args = {'num_workers': 0, 'pin_memory': False}\n",
    "    def _init_fn(worker_id):\n",
    "        np.random.seed(int(seed))\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,num_workers=0,pin_memory=True,shuffle=shuffle)\n",
    "    \n",
    "forget_dataset = copy.deepcopy(marked_loader.dataset)\n",
    "marked = forget_dataset.targets < 0\n",
    "forget_dataset.data = forget_dataset.data[marked]\n",
    "forget_dataset.targets = - forget_dataset.targets[marked] - 1\n",
    "forget_loader = replace_loader_dataset(train_loader_full, forget_dataset, batch_size=args.forget_bs, seed=seed, shuffle=True)\n",
    "\n",
    "retain_dataset = copy.deepcopy(marked_loader.dataset)\n",
    "marked = retain_dataset.targets >= 0\n",
    "retain_dataset.data = retain_dataset.data[marked]\n",
    "retain_dataset.targets = retain_dataset.targets[marked]\n",
    "retain_loader = replace_loader_dataset(train_loader_full, retain_dataset, batch_size=args.retain_bs, seed=seed, shuffle=True)\n",
    "\n",
    "assert(len(forget_dataset) + len(retain_dataset) == len(train_loader_full.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "112\n",
      "10000\n",
      "160\n",
      "{0: 16, 1: 16, 2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 16, 8: 16, 9: 16}\n"
     ]
    }
   ],
   "source": [
    "print (len(forget_loader.dataset))\n",
    "print (len(retain_loader.dataset))\n",
    "print (len(test_loader_full.dataset))\n",
    "print (len(train_loader_full.dataset))\n",
    "from collections import Counter\n",
    "print(dict(Counter(train_loader_full.dataset.targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRUB Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.optim = 'adam'\n",
    "args.gamma = 1\n",
    "args.alpha = 0.5\n",
    "args.beta = 0\n",
    "args.smoothing = 0.5\n",
    "args.msteps = 3\n",
    "args.clip = 0.2\n",
    "args.sstart = 10\n",
    "args.kd_T = 2\n",
    "args.distill = 'kd'\n",
    "\n",
    "args.sgda_epochs = 10\n",
    "args.sgda_learning_rate = 0.0005\n",
    "args.lr_decay_epochs = [5,8,9]\n",
    "args.lr_decay_rate = 0.1\n",
    "args.sgda_weight_decay = 0.1#5e-4\n",
    "args.sgda_momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = copy.deepcopy(teacher)\n",
    "model_s = copy.deepcopy(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from https://github.com/ojus1/SmoothedGradientDescentAscent/blob/main/SGDA.py\n",
    "#For SGDA smoothing\n",
    "beta = 0.1\n",
    "def avg_fn(averaged_model_parameter, model_parameter, num_averaged): return (\n",
    "    1 - beta) * averaged_model_parameter + beta * model_parameter\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(\n",
    "    model_s, avg_fn=avg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list = nn.ModuleList([])\n",
    "module_list.append(model_s)\n",
    "trainable_list = nn.ModuleList([])\n",
    "trainable_list.append(model_s)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_div = DistillKL(args.kd_T)\n",
    "criterion_kd = DistillKL(args.kd_T)\n",
    "\n",
    "\n",
    "criterion_list = nn.ModuleList([])\n",
    "criterion_list.append(criterion_cls)    # classification loss\n",
    "criterion_list.append(criterion_div)    # KL divergence loss, original knowledge distillation\n",
    "criterion_list.append(criterion_kd)     # other knowledge distillation loss\n",
    "\n",
    "# optimizer\n",
    "if args.optim == \"sgd\":\n",
    "    optimizer = optim.SGD(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          momentum=args.sgda_momentum,\n",
    "                          weight_decay=args.sgda_weight_decay)\n",
    "elif args.optim == \"adam\": \n",
    "    optimizer = optim.Adam(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          weight_decay=args.sgda_weight_decay)\n",
    "elif args.optim == \"rmsp\":\n",
    "    optimizer = optim.RMSprop(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          momentum=args.sgda_momentum,\n",
    "                          weight_decay=args.sgda_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list.append(model_t)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    module_list.cuda()\n",
    "    criterion_list.cuda()\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    cudnn.benchmark = True\n",
    "    swa_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> scrub unlearning ...\n",
      " * Acc@1 38.393 \n",
      "maximize loss: -0.00\t minimize loss: 2.13\t train_acc: 38.39285659790039\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 43.750 \n",
      "maximize loss: 0.14\t minimize loss: 2.15\t train_acc: 43.75\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 45.536 \n",
      "maximize loss: 0.24\t minimize loss: 2.19\t train_acc: 45.53571319580078\n",
      "==> scrub unlearning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 45.536 \n",
      "maximize loss: 0.00\t minimize loss: 2.23\t train_acc: 45.53571319580078\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 48.214 \n",
      "maximize loss: 0.00\t minimize loss: 2.25\t train_acc: 48.21428680419922\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 53.571 \n",
      "maximize loss: 0.00\t minimize loss: 2.27\t train_acc: 53.57143020629883\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 51.786 \n",
      "maximize loss: 0.00\t minimize loss: 2.28\t train_acc: 51.78571319580078\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 52.679 \n",
      "maximize loss: 0.00\t minimize loss: 2.28\t train_acc: 52.67856979370117\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 53.571 \n",
      "maximize loss: 0.00\t minimize loss: 2.28\t train_acc: 53.57143020629883\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 53.571 \n",
      "maximize loss: 0.00\t minimize loss: 2.28\t train_acc: 53.57143020629883\n"
     ]
    }
   ],
   "source": [
    "acc_rs = []\n",
    "acc_fs = []\n",
    "acc_ts = []\n",
    "for epoch in range(1, args.sgda_epochs + 1):\n",
    "\n",
    "    lr = sgda_adjust_learning_rate(epoch, args, optimizer)\n",
    "\n",
    "    print(\"==> scrub unlearning ...\")\n",
    "\n",
    "    acc_r, acc5_r, loss_r = validate(retain_loader, model_s, criterion_cls, args, True)\n",
    "    acc_f, acc5_f, loss_f = validate(forget_loader, model_s, criterion_cls, args, True)\n",
    "    acc_rs.append(100-acc_r.item())\n",
    "    acc_fs.append(100-acc_f.item())\n",
    "\n",
    "    maximize_loss = 0\n",
    "    if epoch <= args.msteps:\n",
    "        maximize_loss = train_distill(epoch, forget_loader, module_list, swa_model, criterion_list, optimizer, args, \"maximize\")\n",
    "    train_acc, train_loss = train_distill(epoch, retain_loader, module_list, swa_model, criterion_list, optimizer, args, \"minimize\",)\n",
    "    if epoch >= args.sstart:\n",
    "        swa_model.update_parameters(model_s)\n",
    "\n",
    "    print (\"maximize loss: {:.2f}\\t minimize loss: {:.2f}\\t train_acc: {}\".format(maximize_loss, train_loss, train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "indices = list(range(0,len(acc_rs)))\n",
    "plt.plot(indices, acc_rs, marker='*', alpha=1, label='retain-set')\n",
    "plt.plot(indices, acc_fs, marker='o', alpha=1, label='forget-set')\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.title('scrub retain- and forget- set error',size=18)\n",
    "plt.xlabel('epoch',size=14)\n",
    "plt.ylabel('error',size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTK based Forgetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NTK Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_w_utils(model_init,dataloader,name='complete'):\n",
    "    model_init.eval()\n",
    "    dataloader = torch.utils.data.DataLoader(dataloader.dataset, batch_size=1, shuffle=False)\n",
    "    G_list = []\n",
    "    f0_minus_y = []\n",
    "    for idx, batch in enumerate(dataloader):#(tqdm(dataloader,leave=False)):\n",
    "        batch = [tensor.to(next(model_init.parameters()).device) for tensor in batch]\n",
    "        input, target = batch\n",
    "        if 'mnist' in args.dataset:\n",
    "            input = input.view(input.shape[0],-1)\n",
    "        target = target.cpu().detach().numpy()\n",
    "        output = model_init(input)\n",
    "        G_sample=[]\n",
    "        for cls in range(num_classes):\n",
    "            grads = torch.autograd.grad(output[0,cls],model_init.parameters(),retain_graph=True)\n",
    "            grads = np.concatenate([g.view(-1).cpu().numpy() for g in grads])\n",
    "            G_sample.append(grads)\n",
    "            G_list.append(grads)\n",
    "        if args.lossfn=='mse':\n",
    "            p = output.cpu().detach().numpy().transpose()\n",
    "            #loss_hess = np.eye(len(p))\n",
    "            target = 2*target-1\n",
    "            f0_y_update = p-target\n",
    "        elif args.lossfn=='ce':\n",
    "            p = torch.nn.functional.softmax(output,dim=1).cpu().detach().numpy().transpose()\n",
    "            p[target]-=1\n",
    "            f0_y_update = copy.deepcopy(p)\n",
    "        f0_minus_y.append(f0_y_update)\n",
    "    return np.stack(G_list).transpose(),np.vstack(f0_minus_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobians and Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk_time = 0\n",
    "model_init = ntk_init(init_checkpoint,args.seed)\n",
    "t1 = time.time()\n",
    "G_r,f0_minus_y_r = delta_w_utils(copy.deepcopy(model),retain_loader,'complete')\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "np.save('NTK_data/G_r.npy',G_r)\n",
    "np.save('NTK_data/f0_minus_y_r.npy',f0_minus_y_r)\n",
    "del G_r, f0_minus_y_r\n",
    "\n",
    "model_init = ntk_init(init_checkpoint,args.seed)\n",
    "t1 = time.time()\n",
    "G_f,f0_minus_y_f = delta_w_utils(copy.deepcopy(model),forget_loader,'retain') \n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "np.save('NTK_data/G_f.npy',G_f)\n",
    "np.save('NTK_data/f0_minus_y_f.npy',f0_minus_y_f)\n",
    "del G_f, f0_minus_y_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_r = np.load('NTK_data/G_r.npy')\n",
    "G_f = np.load('NTK_data/G_f.npy')\n",
    "G = np.concatenate([G_r,G_f],axis=1)\n",
    "\n",
    "np.save('NTK_data/G.npy',G)\n",
    "del G, G_f, G_r\n",
    "\n",
    "f0_minus_y_r = np.load('NTK_data/f0_minus_y_r.npy')\n",
    "f0_minus_y_f = np.load('NTK_data/f0_minus_y_f.npy')\n",
    "f0_minus_y = np.concatenate([f0_minus_y_r,f0_minus_y_f])\n",
    "\n",
    "np.save('NTK_data/f0_minus_y.npy',f0_minus_y)\n",
    "del f0_minus_y, f0_minus_y_r, f0_minus_y_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only requires access to the gradients and the initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w_lin(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.load('NTK_data/G.npy')\n",
    "t1 = time.time()\n",
    "theta = G.transpose().dot(G) + num_total*args.weight_decay*np.eye(G.shape[1])\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "del G\n",
    "\n",
    "t1 = time.time()\n",
    "theta_inv = np.linalg.inv(theta)\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "np.save('NTK_data/theta.npy',theta)\n",
    "del theta\n",
    "\n",
    "G = np.load('NTK_data/G.npy')\n",
    "f0_minus_y = np.load('NTK_data/f0_minus_y.npy')\n",
    "t1 = time.time()\n",
    "w_complete = -G.dot(theta_inv.dot(f0_minus_y))\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "np.save('NTK_data/theta_inv.npy',theta_inv)\n",
    "np.save('NTK_data/w_complete.npy',w_complete)\n",
    "\n",
    "del G, f0_minus_y, theta_inv, w_complete "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w_lin(D_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_r = np.load('NTK_data/G_r.npy')\n",
    "t1 = time.time()\n",
    "theta_r = G_r.transpose().dot(G_r) + num_to_retain*args.weight_decay*np.eye(G_r.shape[1])\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "del G_r\n",
    "\n",
    "t1 = time.time()\n",
    "theta_r_inv = np.linalg.inv(theta_r)\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "np.save('NTK_data/theta_r.npy',theta_r)\n",
    "del theta_r\n",
    "\n",
    "G_r = np.load('NTK_data/G_r.npy')\n",
    "f0_minus_y_r = np.load('NTK_data/f0_minus_y_r.npy')\n",
    "t1 = time.time()\n",
    "w_retain = -G_r.dot(theta_r_inv.dot(f0_minus_y_r))\n",
    "t2 = time.time()\n",
    "ntk_time += t2-t1\n",
    "\n",
    "np.save('NTK_data/theta_r_inv.npy',theta_r_inv)\n",
    "np.save('NTK_data/w_retain.npy',w_retain)\n",
    "\n",
    "del G_r, f0_minus_y_r, theta_r_inv, w_retain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrubbing Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Scrubbing Direction\n",
    "w_complete = np.load('NTK_data/w_complete.npy')\n",
    "w_retain = np.load('NTK_data/w_retain.npy')\n",
    "delta_w = (w_retain-w_complete).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_w_copy = copy.deepcopy(delta_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Change in Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Norm-: 0.3259751498699188\n",
      "Predtn Norm-: 27.428124351775097\n",
      "Actual Scale: 0.011884704389158215\n"
     ]
    }
   ],
   "source": [
    "delta_w_actual = vectorize_params(model0)-vectorize_params(model)\n",
    "\n",
    "print(f'Actual Norm-: {np.linalg.norm(delta_w_actual)}')\n",
    "print(f'Predtn Norm-: {np.linalg.norm(delta_w)}')\n",
    "scale_ratio = np.linalg.norm(delta_w_actual)/np.linalg.norm(delta_w)\n",
    "print('Actual Scale: {}'.format(scale_ratio))\n",
    "log_dict['actual_scale_ratio']=scale_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trapezium Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta w -------: 27.428124351775097\n",
      "Inner Product--: -0.9993777226557279\n",
      "Angle----------:  1.5355162504580755\n",
      "Pred Act Norm--:  82.19381281967924\n",
      "Predicted Scale:  2.9966982709249605\n"
     ]
    }
   ],
   "source": [
    "m_pred_error = vectorize_params(model)-vectorize_params(model_init)-w_retain.squeeze()\n",
    "print(f\"Delta w -------: {np.linalg.norm(delta_w)}\")\n",
    "\n",
    "inner = np.inner(delta_w/np.linalg.norm(delta_w),m_pred_error/np.linalg.norm(m_pred_error))\n",
    "print(f\"Inner Product--: {inner}\")\n",
    "\n",
    "if inner<0:\n",
    "    angle = np.arccos(inner)-np.pi/2\n",
    "    print(f\"Angle----------:  {angle}\")\n",
    "\n",
    "    predicted_norm=np.linalg.norm(delta_w) + 2*np.sin(angle)*np.linalg.norm(m_pred_error)\n",
    "    print(f\"Pred Act Norm--:  {predicted_norm}\")\n",
    "else:\n",
    "    angle = np.arccos(inner) \n",
    "    print(f\"Angle----------:  {angle}\")\n",
    "\n",
    "    predicted_norm=np.linalg.norm(delta_w) + 2*np.cos(angle)*np.linalg.norm(m_pred_error)\n",
    "    print(f\"Pred Act Norm--:  {predicted_norm}\")\n",
    "\n",
    "predicted_scale=predicted_norm/np.linalg.norm(delta_w)\n",
    "predicted_scale\n",
    "print(f\"Predicted Scale:  {predicted_scale}\")\n",
    "log_dict['predicted_scale_ratio']=predicted_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Inner Product between Prediction and Actual Scrubbing Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NIP(v1,v2):\n",
    "    nip = (np.inner(v1/np.linalg.norm(v1),v2/np.linalg.norm(v2)))\n",
    "    print(nip)\n",
    "    return nip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023562426898978486\n"
     ]
    }
   ],
   "source": [
    "nip=NIP(delta_w_actual,delta_w)\n",
    "log_dict['nip']=nip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_w_dict(delta_w,model):\n",
    "    # Give normalized delta_w\n",
    "    delta_w_dict = OrderedDict()\n",
    "    params_visited = 0\n",
    "    for k,p in model.named_parameters():\n",
    "        num_params = np.prod(list(p.shape))\n",
    "        update_params = delta_w[params_visited:params_visited+num_params]\n",
    "        delta_w_dict[k] = torch.Tensor(update_params).view_as(p)\n",
    "        params_visited+=num_params\n",
    "    return delta_w_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "def get_metrics(model,dataloader,criterion,samples_correctness=False,use_bn=False,delta_w=None,scrub_act=False):\n",
    "    activations=[]\n",
    "    predictions=[]\n",
    "    if use_bn:\n",
    "        model.train()\n",
    "        dataloader = torch.utils.data.DataLoader(retain_loader.dataset, batch_size=128, shuffle=True)\n",
    "        for i in range(10):\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = data.to(args.device), target.to(args.device)            \n",
    "                output = model(data)\n",
    "    dataloader = torch.utils.data.DataLoader(dataloader.dataset, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    mult = 0.5 if args.lossfn=='mse' else 1\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(args.device), target.to(args.device)            \n",
    "        if args.lossfn=='mse':\n",
    "            target=(2*target-1)\n",
    "            target = target.type(torch.cuda.FloatTensor).unsqueeze(1)\n",
    "        if 'mnist' in args.dataset:\n",
    "            data=data.view(data.shape[0],-1)\n",
    "        output = model(data)\n",
    "        loss = mult*criterion(output, target)\n",
    "        if samples_correctness:\n",
    "            activations.append(torch.nn.functional.softmax(output,dim=1).cpu().detach().numpy().squeeze())\n",
    "            predictions.append(get_error(output,target))\n",
    "        metrics.update(n=data.size(0), loss=loss.item(), error=get_error(output, target))\n",
    "    if samples_correctness:\n",
    "        return metrics.avg,np.stack(activations),np.array(predictions)\n",
    "    else:\n",
    "        return metrics.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activations_predictions(model,dataloader,name):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    metrics,activations,predictions=get_metrics(model,dataloader,criterion,True)\n",
    "    print(f\"{name} -> Loss:{np.round(metrics['loss'],3)}, Error:{metrics['error']}\")\n",
    "    log_dict[f\"{name}_loss\"]=metrics['loss']\n",
    "    log_dict[f\"{name}_error\"]=metrics['error']\n",
    "\n",
    "    return activations,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_distance(l1,l2,name):\n",
    "    dist = np.sum(np.abs(l1-l2))\n",
    "    print(f\"Predictions Distance {name} -> {dist}\")\n",
    "    log_dict[f\"{name}_predictions\"]=dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activations_distance(a1,a2,name):\n",
    "    dist = np.linalg.norm(a1-a2,ord=1,axis=1).mean()\n",
    "    print(f\"Activations Distance {name} -> {dist}\")\n",
    "    log_dict[f\"{name}_activations\"]=dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub using NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=predicted_scale\n",
    "direction = get_delta_w_dict(delta_w,model)\n",
    "\n",
    "model_scrub = copy.deepcopy(model)\n",
    "for k,p in model_scrub.named_parameters():\n",
    "    p.data += (direction[k]*scale).to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher Forgetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune and Fisher Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "def get_metrics(model,dataloader,criterion,samples_correctness=False,use_bn=False,delta_w=None,scrub_act=False):\n",
    "    activations=[]\n",
    "    predictions=[]\n",
    "    if use_bn:\n",
    "        model.train()\n",
    "        dataloader = torch.utils.data.DataLoader(retain_loader.dataset, batch_size=128, shuffle=True)\n",
    "        for i in range(10):\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = data.to(args.device), target.to(args.device)            \n",
    "                output = model(data)\n",
    "    dataloader = torch.utils.data.DataLoader(dataloader.dataset, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    mult = 0.5 if args.lossfn=='mse' else 1\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(args.device), target.to(args.device)            \n",
    "        if args.lossfn=='mse':\n",
    "            target=(2*target-1)\n",
    "            target = target.type(torch.cuda.FloatTensor).unsqueeze(1)\n",
    "        if 'mnist' in args.dataset:\n",
    "            data=data.view(data.shape[0],-1)\n",
    "        output = model(data)\n",
    "        if scrub_act:\n",
    "            G = []\n",
    "            for cls in range(num_classes):\n",
    "                grads = torch.autograd.grad(output[0,cls],model.parameters(),retain_graph=True)\n",
    "                grads = torch.cat([g.view(-1) for g in grads])\n",
    "                G.append(grads)\n",
    "            grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=False)\n",
    "            G = torch.stack(G).pow(2)\n",
    "            delta_f = torch.matmul(G,delta_w)\n",
    "            output += delta_f.sqrt()*torch.empty_like(delta_f).normal_()\n",
    "\n",
    "        loss = mult*criterion(output, target)\n",
    "        if samples_correctness:\n",
    "            activations.append(torch.nn.functional.softmax(output,dim=1).cpu().detach().numpy().squeeze())\n",
    "            predictions.append(get_error(output,target))\n",
    "        metrics.update(n=data.size(0), loss=loss.item(), error=get_error(output, target))\n",
    "    if samples_correctness:\n",
    "        return metrics.avg,np.stack(activations),np.array(predictions)\n",
    "    else:\n",
    "        return metrics.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_penalty(model,model_init,weight_decay):\n",
    "    l2_loss = 0\n",
    "    for (k,p),(k_init,p_init) in zip(model.named_parameters(),model_init.named_parameters()):\n",
    "        if p.requires_grad:\n",
    "            l2_loss += (p-p_init).pow(2).sum()\n",
    "    l2_loss *= (weight_decay/2.)\n",
    "    return l2_loss\n",
    "\n",
    "def run_train_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader, \n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, split: str, epoch: int, ignore_index=None,\n",
    "                    negative_gradient=False, negative_multiplier=-1, random_labels=False,\n",
    "                    quiet=False,delta_w=None,scrub_act=False):\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()    \n",
    "    num_labels = data_loader.dataset.targets.max().item() + 1\n",
    "    \n",
    "    with torch.set_grad_enabled(split != 'test'):\n",
    "        for idx, batch in enumerate(tqdm(data_loader, leave=False)):\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            input, target = batch\n",
    "            output = model(input)\n",
    "            if split=='test' and scrub_act:\n",
    "                G = []\n",
    "                for cls in range(num_classes):\n",
    "                    grads = torch.autograd.grad(output[0,cls],model.parameters(),retain_graph=True)\n",
    "                    grads = torch.cat([g.view(-1) for g in grads])\n",
    "                    G.append(grads)\n",
    "                grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=False)\n",
    "                G = torch.stack(G).pow(2)\n",
    "                delta_f = torch.matmul(G,delta_w)\n",
    "                output += delta_f.sqrt()*torch.empty_like(delta_f).normal_()\n",
    "            loss = loss_fn(output, target) + l2_penalty(model,model_init,args.weight_decay)\n",
    "            metrics.update(n=input.size(0), loss=loss_fn(output,target).item(), error=get_error(output, target))\n",
    "            \n",
    "            if split != 'test':\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    if not quiet:\n",
    "        log_metrics(split, metrics, epoch)\n",
    "    return metrics.avg\n",
    "\n",
    "def run_neggrad_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader, \n",
    "                    forget_loader: torch.utils.data.DataLoader,\n",
    "                    alpha: float,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, split: str, epoch: int, ignore_index=None,\n",
    "                    quiet=False):\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()    \n",
    "    num_labels = data_loader.dataset.targets.max().item() + 1\n",
    "    \n",
    "    with torch.set_grad_enabled(split != 'test'):\n",
    "        for idx, (batch_retain,batch_forget) in enumerate(tqdm(zip(data_loader,cycle(forget_loader)), leave=False)):\n",
    "            batch_retain = [tensor.to(next(model.parameters()).device) for tensor in batch_retain]\n",
    "            batch_forget = [tensor.to(next(model.parameters()).device) for tensor in batch_forget]\n",
    "            input_r, target_r = batch_retain\n",
    "            input_f, target_f = batch_forget\n",
    "            output_r = model(input_r)\n",
    "            output_f = model(input_f)\n",
    "            loss = alpha*(loss_fn(output_r, target_r) + l2_penalty(model,model_init,args.weight_decay)) - (1-alpha)*loss_fn(output_f, target_f)\n",
    "            metrics.update(n=input_r.size(0), loss=loss_fn(output_r,target_r).item(), error=get_error(output_r, target_r))\n",
    "            if split != 'test':\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    if not quiet:\n",
    "        log_metrics(split, metrics, epoch)\n",
    "    return metrics.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model: nn.Module, data_loader: torch.utils.data.DataLoader, lr=0.01, epochs=10, quiet=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        run_train_epoch(model, model_init, data_loader, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)\n",
    "        #train_vanilla(epoch, data_loader, model, loss_fn, optimizer, args)\n",
    "\n",
    "def negative_grad(model: nn.Module, data_loader: torch.utils.data.DataLoader, forget_loader: torch.utils.data.DataLoader, alpha: float, lr=0.01, epochs=10, quiet=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        run_neggrad_epoch(model, model_init, data_loader, forget_loader, alpha, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)\n",
    "        #train_negrad(epoch, data_loader, forget_loader, model, loss_fn, optimizer,  alpha)\n",
    "\n",
    "def fk_fientune(model: nn.Module, data_loader: torch.utils.data.DataLoader, args, lr=0.01, epochs=10, quiet=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        sgda_adjust_learning_rate(epoch, args, optimizer)\n",
    "        run_train_epoch(model, model_init, data_loader, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)\n",
    "        #train_negrad(epoch, data_loader, forget_loader, model, loss_fn, optimizer,  alpha)\n",
    "def test(model, data_loader):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model_init=copy.deepcopy(model)\n",
    "    return run_train_epoch(model, model_init, data_loader, loss_fn, optimizer=None, split='test', epoch=epoch, ignore_index=None, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readout_retrain(model, data_loader, test_loader, lr=0.1, epochs=500, threshold=0.01, quiet=True):\n",
    "    torch.manual_seed(seed)\n",
    "    model = copy.deepcopy(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    sampler = torch.utils.data.RandomSampler(data_loader.dataset, replacement=True, num_samples=500)\n",
    "    data_loader_small = torch.utils.data.DataLoader(data_loader.dataset, batch_size=data_loader.batch_size, sampler=sampler, num_workers=data_loader.num_workers)\n",
    "    metrics = []\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        metrics.append(run_train_epoch(model, model_init, test_loader, loss_fn, optimizer, split='test', epoch=epoch, ignore_index=None, quiet=quiet))\n",
    "        if metrics[-1]['loss'] <= threshold:\n",
    "            break\n",
    "        run_train_epoch(model, model_init, data_loader_small, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)\n",
    "    return epoch, metrics\n",
    "\n",
    "def extract_retrain_time(metrics, threshold=0.1):\n",
    "    losses = np.array([m['loss'] for m in metrics])\n",
    "    return np.argmax(losses < threshold)\n",
    "\n",
    "def all_readouts(model,thresh=0.1,name='method'):\n",
    "    train_loader = torch.utils.data.DataLoader(train_loader_full.dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    retrain_time, _ = readout_retrain(model, train_loader, forget_loader, epochs=100, lr=0.1, threshold=thresh)\n",
    "    test_error = test(model, test_loader_full)['error']\n",
    "    forget_error = test(model, forget_loader)['error']\n",
    "    retain_error = test(model, retain_loader)['error']\n",
    "    print(f\"{name} ->\"\n",
    "          f\"\\tFull test error: {test_error:.2%}\"\n",
    "          f\"\\tForget error: {forget_error:.2%}\\tRetain error: {retain_error:.2%}\"\n",
    "          f\"\\tFine-tune time: {retrain_time+1} steps\")\n",
    "    log_dict[f\"{name}_retrain_time\"]=retrain_time+1\n",
    "    return(dict(test_error=test_error, forget_error=forget_error, retain_error=retain_error, retrain_time=retrain_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scrubf = copy.deepcopy(model_scrub)\n",
    "modelf = copy.deepcopy(model)\n",
    "modelf0 = copy.deepcopy(model0)\n",
    "\n",
    "for p in itertools.chain(modelf.parameters(), modelf0.parameters(), model_scrubf.parameters()):\n",
    "    p.data0 = copy.deepcopy(p.data.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(dataset, model):\n",
    "    model.eval()\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.grad_acc = 0\n",
    "        p.grad2_acc = 0\n",
    "    \n",
    "    for data, orig_target in tqdm(train_loader):\n",
    "        data, orig_target = data.to(args.device), orig_target.to(args.device)\n",
    "        output = model(data)\n",
    "        prob = F.softmax(output, dim=-1).data\n",
    "\n",
    "        for y in range(output.shape[1]):\n",
    "            target = torch.empty_like(orig_target).fill_(y)\n",
    "            loss = loss_fn(output, target)\n",
    "            model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            for p in model.parameters():\n",
    "                if p.requires_grad:\n",
    "                    p.grad_acc += (orig_target == target).float() * p.grad.data\n",
    "                    p.grad2_acc += prob[:, y] * p.grad.data.pow(2)\n",
    "    for p in model.parameters():\n",
    "        p.grad_acc /= len(train_loader)\n",
    "        p.grad2_acc /= len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eef5ed5c307843b6be8635fc3efa0488"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e3b91a2ca334072bbf881ea78cb80f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/112 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "620b337bc6054dcd9503af998b77420d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hessian(retain_loader.dataset, model_scrubf)\n",
    "hessian(retain_loader.dataset, modelf)\n",
    "hessian(retain_loader.dataset, modelf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_var(p, is_base_dist=False, alpha=3e-6):\n",
    "    var = copy.deepcopy(1./(p.grad2_acc+1e-8))\n",
    "    var = var.clamp(max=1e3)\n",
    "    if p.size(0) == num_classes:\n",
    "        var = var.clamp(max=1e2)\n",
    "    var = alpha * var\n",
    "    \n",
    "    if p.ndim > 1:\n",
    "        var = var.mean(dim=1, keepdim=True).expand_as(p).clone()\n",
    "    if not is_base_dist:\n",
    "        mu = copy.deepcopy(p.data0.clone())\n",
    "    else:\n",
    "        mu = copy.deepcopy(p.data0.clone())\n",
    "    if p.size(0) == num_classes and num_to_forget is None:\n",
    "        mu[class_to_forget] = 0\n",
    "        var[class_to_forget] = 0.0001\n",
    "    if p.size(0) == num_classes:\n",
    "        # Last layer\n",
    "        var *= 10\n",
    "    elif p.ndim == 1:\n",
    "        # BatchNorm\n",
    "        var *= 10\n",
    "#         var*=1\n",
    "    return mu, var\n",
    "\n",
    "def kl_divergence_fisher(mu0, var0, mu1, var1):\n",
    "    return ((mu1 - mu0).pow(2)/var0 + var1/var0 - torch.log(var1/var0) - 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Noise in Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight 1278.3\n",
      "layers.0.bias 37.8\n",
      "layers.2.weight 96.4\n",
      "layers.2.bias 225.2\n",
      "Total: 1637.6112213134766\n"
     ]
    }
   ],
   "source": [
    "# Computes the amount of information not forgotten at all layers using the given alpha\n",
    "alpha = 1e-7\n",
    "total_kl = 0\n",
    "torch.manual_seed(seed)\n",
    "for (k, p), (k0, p0) in zip(modelf.named_parameters(), modelf0.named_parameters()):\n",
    "    mu0, var0 = get_mean_var(p, False, alpha=alpha)\n",
    "    mu1, var1 = get_mean_var(p0, True, alpha=alpha)\n",
    "    kl = kl_divergence_fisher(mu0, var0, mu1, var1).item()\n",
    "    total_kl += kl\n",
    "    print(k, f'{kl:.1f}')\n",
    "print(\"Total:\", total_kl)\n",
    "log_dict['fisher_info']=total_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_dir = []\n",
    "alpha = 1e-6\n",
    "torch.manual_seed(seed)\n",
    "for i, p in enumerate(modelf.parameters()):\n",
    "    mu, var = get_mean_var(p, False, alpha=alpha)\n",
    "    p.data = mu + var.sqrt() * torch.empty_like(p.data0).normal_()\n",
    "    fisher_dir.append(var.sqrt().view(-1).cpu().detach().numpy())\n",
    "\n",
    "for i, p in enumerate(modelf0.parameters()):\n",
    "    mu, var = get_mean_var(p, False, alpha=alpha)\n",
    "    p.data = mu + var.sqrt() * torch.empty_like(p.data0).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50228fabec5d4ed08d24de12852ba530"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {'loss': 2.089437280382429, 'error': 0.6607142857142857})\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b09698199bf402cbb65c61221c532d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {'loss': 2.0233612060546875, 'error': 0.6666666567325592})\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad2a8cb00d0547438b5cb16288d63716"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {'loss': 2.1507210731506348, 'error': 0.699999988079071})\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22d7febbd40a453b82ff5dead0ffb83b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {'loss': 2.141480310821533, 'error': 0.7211})\n"
     ]
    }
   ],
   "source": [
    "print(test(modelf, retain_loader))\n",
    "print(test(modelf, forget_loader))\n",
    "print(test(modelf, valid_loader_full))\n",
    "print(test(modelf, test_loader_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bfd88d6c0db48aca7c71b8632a20b4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f7676f1dad944d09b493a9c2c95ee17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ca39a9e0b3541fcb2c7c3762ed3ea21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c327d3b523814db9a9fe0370f747d1ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5af7e6fb3d104eefb0b12b40c32dfaa8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5bbd1d286704c3aa330d04cd85909fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14cb2cb9f6e8412eab84a48dea1595bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02a7649de7e34232b021d89380acb756"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b796fd0d577f4959929ce295311daa4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e09e3faabb045d0ba4cc70c66cbe599"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = copy.deepcopy(model)\n",
    "retain_loader = replace_loader_dataset(train_loader_full,retain_dataset, seed=seed, batch_size=args.batch_size, shuffle=True)    \n",
    "finetune(model_ft, retain_loader, epochs=10, quiet=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4ed3eed9ca44bd88a69a2694d7c1a2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36b8d6a038d0444db39a301eb8f20c09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14e522b9e59d4c4d8a230156d904a2fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ddbcd9a8417411591a4697867d346d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72f18ce85eb64d1a9f86680fbf553811"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5092a6c32caa45b8b5cac46c677d2f9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09a443b8c7804d9295e2a5c93f83f998"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "defc2005167f4726aff7475a2590bc65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4a9943d613545b391c2997dd5fceadf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "754526fa59294211a70d3300ba170e38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args.ng_alpha = 0.95\n",
    "args.ng_epochs = 10\n",
    "args.ng_lr = 0.01\n",
    "model_ng = copy.deepcopy(model)    \n",
    "negative_grad(model_ng, retain_loader, forget_loader, alpha=args.ng_alpha, epochs=args.ng_epochs, quiet=True, lr=args.ng_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catastrophic Forgetting k layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m         param\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n\u001B[1;32m     24\u001B[0m fk_fientune(model_cfk, retain_loader, args\u001B[38;5;241m=\u001B[39margs, epochs\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mcfk_epochs, quiet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, lr\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mcfk_lr)\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args.lr_decay_epochs = [10,15,20]\n",
    "args.cfk_lr = 0.01\n",
    "args.cfk_epochs = 10\n",
    "\n",
    "model_cfk = copy.deepcopy(model)\n",
    "\n",
    "for param in model_cfk.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "if args.model == 'allcnn':\n",
    "    layers = [9]\n",
    "    for k in layers:\n",
    "        for param in model_cfk.features[k].parameters():\n",
    "            param.requires_grad_(True)\n",
    "    \n",
    "elif args.model == \"resnet\":\n",
    "    for param in model_cfk.layer4.parameters():\n",
    "        param.requires_grad_(True)\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "fk_fientune(model_cfk, retain_loader, args=args, epochs=args.cfk_epochs, quiet=True, lr=args.cfk_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Unlearning k layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "' The last block and classifier of allcnn\\nAllCNN(\\n  (features): Sequential(\\n    ...\\n    (9): Conv(\\n      (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      (2): ReLU()\\n    )\\n    (10): AvgPool2d(kernel_size=8, stride=8, padding=0)\\n    (11): Flatten()\\n  )\\n  (classifier): Sequential(\\n    (0): Linear(in_features=192, out_features=5, bias=True)\\n  )\\n)\\n'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The last block and classifier of resnet-18\n",
    "(layer4): Sequential(\n",
    "    (0): _ResBlock(\n",
    "      (bn1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (conv1): Conv2d(102, 204, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "      (bn2): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (conv2): Conv2d(204, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (shortcut): Sequential(\n",
    "        (0): Conv2d(102, 204, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "      )\n",
    "    )\n",
    "    (1): _ResBlock(\n",
    "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (conv1): Conv2d(204, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (bn2): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (conv2): Conv2d(204, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    )\n",
    "  )\n",
    "(linear): Linear(in_features=204, out_features=5, bias=True)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" The last block and classifier of allcnn\n",
    "AllCNN(\n",
    "  (features): Sequential(\n",
    "    ...\n",
    "    (9): Conv(\n",
    "      (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "    )\n",
    "    (10): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
    "    (11): Flatten()\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=192, out_features=5, bias=True)\n",
    "  )\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 71\u001B[0m\n\u001B[1;32m     68\u001B[0m         param\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 71\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n\u001B[1;32m     73\u001B[0m fk_fientune(model_euk, retain_loader, epochs\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39meuk_epochs, quiet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, lr\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39meuk_lr, args\u001B[38;5;241m=\u001B[39margs)\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args.lr_decay_epochs = [10,15,20]\n",
    "args.euk_lr = 0.01\n",
    "args.euk_epochs = training_epochs\n",
    "model_euk = copy.deepcopy(model)\n",
    "\n",
    "for param in model_euk.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "if args.model == 'allcnn':\n",
    "    with torch.no_grad():\n",
    "        for k in layers:\n",
    "            for i in range(0,3):\n",
    "                try:\n",
    "                    model_euk.features[k][i].weight.copy_(model_initial.features[k][i].weight)\n",
    "                except:\n",
    "                    print (\"block {}, layer {} does not have weights\".format(k,i))\n",
    "                try:\n",
    "                    model_euk.features[k][i].bias.copy_(model_initial.features[k][i].bias)\n",
    "                except:\n",
    "                    print (\"block {}, layer {} does not have bias\".format(k,i))\n",
    "        model_euk.classifier[0].weight.copy_(model_initial.classifier[0].weight)\n",
    "        model_euk.classifier[0].bias.copy_(model_initial.classifier[0].bias)\n",
    "    \n",
    "    for k in layers:\n",
    "        for param in model_euk.features[k].parameters():\n",
    "            param.requires_grad_(True)\n",
    "    \n",
    "elif args.model == \"resnet\":\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,2):\n",
    "            try:\n",
    "                model_euk.layer4[i].bn1.weight.copy_(model_initial.layer4[i].bn1.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].bn1.bias.copy_(model_initial.layer4[i].bn1.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv1.weight.copy_(model_initial.layer4[i].conv1.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv1.bias.copy_(model_initial.layer4[i].conv1.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "\n",
    "            try:\n",
    "                model_euk.layer4[i].bn2.weight.copy_(model_initial.layer4[i].bn2.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].bn2.bias.copy_(model_initial.layer4[i].bn2.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv2.weight.copy_(model_initial.layer4[i].conv2.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv2.bias.copy_(model_initial.layer4[i].conv2.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "\n",
    "        model_euk.layer4[0].shortcut[0].weight.copy_(model_initial.layer4[0].shortcut[0].weight)\n",
    "        \n",
    "    for param in model_euk.layer4.parameters():\n",
    "        param.requires_grad_(True)\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "fk_fientune(model_euk, retain_loader, epochs=args.euk_epochs, quiet=True, lr=args.euk_lr, args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original_Model_D_f -> Loss:1.949, Error:0.5\n",
      "1.9491068137979508\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37813c5e06be4881aa48f91f3d2153cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3dbef74d28f4f1685cdf745c776da19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8721a53b8ea045aaaca133e2f6c2ce12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b21f5a4ab384bdcb829c4a86272d11f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ->\tFull test error: 66.09%\tForget error: 50.00%\tRetain error: 62.50%\tFine-tune time: 1 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddd87f587c8e4de1a5d5d2b176b18237"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0417ffa96384e25b1a79e1b7db8c80d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e7edd1955ca489faba6d3fe56987e3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3187ee7fd42444ffb608af3837725e03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0e1705f09c04607a53ee52a06d3aaae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89e6b9dfba3342b6897a0a6f6d30550b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "995912f809e446bcba75f6a9aa85ef23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9645b9540bf74a1984d2f9cb44b20987"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain ->\tFull test error: 75.29%\tForget error: 91.67%\tRetain error: 62.50%\tFine-tune time: 3 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71ed41e4874a4cf2ae67eb05578cdc2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c82ba19f3f94ad884c05706e1549619"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23e87b4eb77445a4a18e875fb79a8d1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39e7327169114a0d98a54dd7756466a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23ddaedb970647e1b65edd9070cd77a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b05b45e94bf445c79bd48df1853e9ac6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune ->\tFull test error: 63.71%\tForget error: 58.33%\tRetain error: 55.36%\tFine-tune time: 2 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "810799e8a5d7437db18b2ea29314cfaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4897b97ab8694c0ba281a60770a03b39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d205e175aee49428d03296591263d23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae7c183c7fc14989af042391ec21fce8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f65f492cd964b1b874f3ca3392568d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a644e79efb9e4cbd97377d298262271a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegGrad ->\tFull test error: 64.49%\tForget error: 62.50%\tRetain error: 56.25%\tFine-tune time: 2 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57b380875e4b438da0be9a390e5a615d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7db300d4715a49c8a64d8c4a38fc508e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c4b2f0cdd9b4cd8b7eb0347ca2333d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa61412cacbd4028b4d8be8bddbe9d35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF-k ->\tFull test error: 66.09%\tForget error: 50.00%\tRetain error: 62.50%\tFine-tune time: 1 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfbd59c7f3ca41b2a52106e63bfa8806"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb2bddc282dd425597e0389f436704aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96afa83cf9e9429da15ae695f10b2a29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5387bcb81f3040689dc0f0eaf7897a52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU-k ->\tFull test error: 66.09%\tForget error: 50.00%\tRetain error: 62.50%\tFine-tune time: 1 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad21b8617db6476eae054c8a1a363ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b830aff9a7b4dc889ab89d1a7fc0f9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d42ecb97582d40af81e4b61dc69435e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c4918199bfb4f1ab7721019aaa77f82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "022c7ae09104494aa6344f72f6150365"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69fc95f4b7e9433ca310973ef2886bb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher ->\tFull test error: 72.11%\tForget error: 66.67%\tRetain error: 66.07%\tFine-tune time: 2 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23463f95a47c495ba724f8824dfb0194"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0680bab147ce48dda6e7da30a66a1fbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c40ab3bf54bd4b45a44db2b483347acd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bb576e1543d41a5b0e4e1e75df7ddfc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8b1b3e6db5044cfb7a288579398a109"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6757d98bf61249088270d6b15b187d0e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44931358e35140869e5dfeed92fa4081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f88a5f05c7b049b3837d579846c1e093"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b107025b5b974754a90f77db552828d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc8aff2f29b5498282adafdf7552421e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a9eff1c66a041ca8dd42f08b30ac4d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ee691afec4d439d87770033be44d9b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a22b5ef1231f4d67ac4ab60dcd3e7a60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4ebdef48b72467d901efca7d581423f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7eef09a4dcc44160b23570b1c1afebb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6239cb5d2fe14b87847aeab361129ecb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7f9f69fa17543fb8a66ef4b96e01826"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11b6f733748e4c3a849210aef3f6a680"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a55b5e92e84d4d8fa2c435243279ff78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f102159b4fe40fe9dfddc05b9fe7d95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4031b0489cea46a5a6f552261cfb5c0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c66b443622c2430fb917b539d8dc9dfa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31868d93f75e4a0991051caaaa3e495f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daedb4c2e9924011add98c58b21e5830"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3512bd05f754563a1a979833871961c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a2abc33fe82482ca100fa7805d0c765"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTK ->\tFull test error: 91.15%\tForget error: 91.67%\tRetain error: 88.39%\tFine-tune time: 12 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6599e47b4a974d0883a94c8701b6c887"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36cd2ce749604d91972392d3dca467b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "810c8deef5724235a065c8cfe70ac2d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/79 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9e6fb8f3e93430ea28620b6725f27fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af0374763ebe4457a5294d13843fbce9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1be70398186f42a1a1d39496f270ff36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRUB ->\tFull test error: 60.70%\tForget error: 64.58%\tRetain error: 46.43%\tFine-tune time: 2 steps\n"
     ]
    }
   ],
   "source": [
    "try: readouts\n",
    "except: readouts = {}\n",
    "\n",
    "_,_=activations_predictions(copy.deepcopy(model),forget_loader,'Original_Model_D_f')\n",
    "thresh=log_dict['Original_Model_D_f_loss']+1e-5\n",
    "print(thresh)\n",
    "readouts[\"a\"] = all_readouts(copy.deepcopy(model),thresh,'Original')\n",
    "readouts[\"b\"] = all_readouts(copy.deepcopy(model0),thresh,'Retrain')\n",
    "readouts[\"c\"] = all_readouts(copy.deepcopy(model_ft),thresh,'Finetune')\n",
    "readouts[\"d\"] = all_readouts(copy.deepcopy(model_ng),thresh,'NegGrad')\n",
    "readouts[\"e\"] = all_readouts(copy.deepcopy(model_cfk),thresh,'CF-k')\n",
    "readouts[\"f\"] = all_readouts(copy.deepcopy(model_euk),thresh,'EU-k')\n",
    "readouts[\"g\"] = all_readouts(copy.deepcopy(modelf),thresh,'Fisher')\n",
    "readouts[\"h\"] = all_readouts(copy.deepcopy(model_scrub),thresh,'NTK')\n",
    "readouts[\"i\"] = all_readouts(copy.deepcopy(model_s),thresh,'SCRUB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
