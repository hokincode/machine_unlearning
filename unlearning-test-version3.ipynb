{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MACHINE UNLEARNING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/2gycpkq57p97cpwvmwvm69m00000gn/T/ipykernel_11220/1703611486.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import utils\n",
    "import variational\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from itertools import cycle\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from typing import List\n",
    "import itertools\n",
    "from tqdm.autonotebook import tqdm\n",
    "from models import *\n",
    "import models\n",
    "from logger import *\n",
    "import wandb\n",
    "from thirdparty.repdistiller.helper.util import adjust_learning_rate as sgda_adjust_learning_rate\n",
    "from thirdparty.repdistiller.distiller_zoo import DistillKL, HintLoss, Attention, Similarity, Correlation, VIDLoss, RKDLoss\n",
    "from thirdparty.repdistiller.distiller_zoo import PKT, ABLoss, FactorTransfer, KDSVD, FSP, NSTLoss\n",
    "from thirdparty.repdistiller.helper.loops import train_distill, train_distill_hide, train_distill_linear, train_vanilla, train_negrad, train_bcu, train_bcu_distill, validate\n",
    "from thirdparty.repdistiller.helper.pretrain import init\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Original Model\n",
    "\n",
    "This cell will run main.py which generate a model and leave many checkpoints for later references. We\n",
    "prepare standard_model_for_pilot for the sake of pilot.\n",
    "\n",
    "dataset: mnist\n",
    "\n",
    "possible datasets, (specifically refer to the dataset_multiclass.py)\n",
    "cifar10,small_cifar5,small_cifar6,small_cifar10,small_binary_cifar10,\n",
    "cifar100,mnist,small_mnist,lacuna100,lacuna10,small_lacuna5,small_lacuna6,small_lacuna10\n",
    "small_binary_lacuna10,tinyimagenet_pretrain,tinyimagenet_finetune,tinyimagenet_finetune5,mix10,mix100\n",
    "\n",
    "model: mlp\n",
    "\n",
    "possible models (refer to models.py)\n",
    "ntk_wide_resnet, is_wide_resnet, wide_resnet, resnet_small, resnet, allcnn_no_bn, ntk_allcnn\n",
    "smallallcnn, allcnn, ntk_mlp, ntk_linear, mlp\n",
    "\n",
    "dataroot: data/MNIST\n",
    "resume from standard_model_for_pilot.pt in checkpoints folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3\n",
      "[Logging in mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_training]\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Number of Classes: 10\n",
      "State OrderedDict([('layers.0.weight', tensor([[-0.0832, -0.0317,  0.0080,  ...,  0.0650, -0.0346, -0.0338],\n",
      "        [-0.0027, -0.0888, -0.0519,  ..., -0.0379,  0.0615,  0.0149],\n",
      "        [-0.1416, -0.0336,  0.0156,  ...,  0.0427,  0.0694,  0.0308],\n",
      "        ...,\n",
      "        [-0.0182, -0.0285,  0.0117,  ...,  0.0094, -0.0225, -0.0526],\n",
      "        [-0.0159,  0.0288, -0.0066,  ...,  0.0381,  0.0633,  0.0451],\n",
      "        [ 0.0131, -0.0608,  0.0516,  ..., -0.0093,  0.0415, -0.0130]])), ('layers.0.bias', tensor([ 0.2570,  0.5360, -0.9828, -0.2736, -0.2282,  0.3082,  0.4359, -0.1057,\n",
      "        -0.0857,  0.2738,  0.0112, -0.4476,  0.2455,  0.2458, -0.0411, -0.3458,\n",
      "        -0.4463,  0.1637, -0.5212,  0.0843,  0.1513, -0.1780, -0.6362,  0.2063,\n",
      "         0.4134,  0.2404, -0.3497, -0.2096, -0.0949, -0.2470,  0.0197,  0.4874])), ('layers.2.weight', tensor([[-0.3519, -0.2154, -0.3365, -0.1412,  0.4156,  0.1818,  0.0200, -0.0604,\n",
      "          0.2205,  0.2322, -0.0053, -0.1393, -0.2035, -0.0579,  0.0095, -0.1644,\n",
      "          0.2235,  0.3024,  0.2238, -0.7361,  0.2985,  0.1393,  0.1623, -0.0921,\n",
      "         -0.0720, -0.1394,  0.2537, -0.1786,  0.1402, -0.0607,  0.0045,  0.0832],\n",
      "        [ 0.3928, -0.1737, -0.1759, -0.4551,  0.2481, -0.4473, -0.0411, -0.2373,\n",
      "         -0.0809,  0.0645,  0.0849,  0.2062, -0.1421, -0.0616,  0.1801, -0.0840,\n",
      "         -0.2335, -0.0692,  0.1498, -0.0470, -0.1586, -0.1081,  0.0933, -0.2024,\n",
      "         -0.1436, -0.1707, -0.0688, -0.5912,  0.1219, -0.1256,  0.2843, -0.1910],\n",
      "        [ 0.4523, -0.3588,  0.0086,  0.0764,  0.1664,  0.4396,  0.0665,  0.4759,\n",
      "         -0.1288, -0.1356, -0.1838,  0.0269, -0.1764, -0.1239,  0.3496, -0.3435,\n",
      "          0.2170, -0.0702,  0.2358,  0.0587, -0.4519, -0.0437,  0.2893, -0.2968,\n",
      "          0.0510,  0.1216,  0.3035,  0.1648, -0.0432,  0.4584,  0.1138, -0.1609],\n",
      "        [-0.2260, -0.0343, -0.1534, -0.0083, -0.2569,  0.0590,  0.2407,  0.2322,\n",
      "         -0.0340,  0.2132,  0.1880,  0.2921, -0.0644, -0.0330,  0.4186,  0.4952,\n",
      "          0.0323,  0.1553, -0.1318, -0.1697,  0.2046, -0.2184,  0.0321, -0.3517,\n",
      "          0.3038, -0.0949, -0.1500,  0.1053, -0.0209, -0.1221, -0.1718, -0.0792],\n",
      "        [ 0.3664,  0.1804, -0.0120,  0.2229, -0.2088,  0.1287, -0.2451, -0.3353,\n",
      "          0.0897, -0.2442,  0.0131, -0.2590, -0.1019,  0.1473,  0.3632,  0.2329,\n",
      "          0.5305,  0.1337, -0.1440,  0.1620,  0.3382, -0.3171,  0.0806,  0.1881,\n",
      "          0.0109,  0.5281, -0.3445,  0.2525, -0.2200, -0.4710,  0.2022, -0.2743],\n",
      "        [ 0.1823, -0.0562, -0.2757, -0.0546, -0.1238, -0.1061,  0.0172, -0.0347,\n",
      "          0.4565,  0.1192, -0.0601,  0.2493, -0.2201,  0.0361,  0.0090,  0.2869,\n",
      "          0.0090, -0.2832, -0.0779, -0.2768, -0.3961, -0.1289,  0.1251, -0.0015,\n",
      "          0.2930,  0.1101,  0.0197,  0.2491,  0.0698,  0.3177,  0.0416,  0.0137],\n",
      "        [-0.3832,  0.2309, -0.1809,  0.1982,  0.0751,  0.0873, -0.1564,  0.0144,\n",
      "         -0.0449, -0.3521,  0.0023, -0.1973, -0.3833,  0.2016, -0.5147, -0.0191,\n",
      "          0.0122, -0.0809,  0.0038,  0.1643,  0.2994,  0.0281, -0.0899, -0.0444,\n",
      "          0.2220,  0.0072, -0.0604, -0.2090, -0.1963, -0.1330, -0.2076,  0.0046],\n",
      "        [-0.2165, -0.1100,  0.0688, -0.3747,  0.4035, -0.0398, -0.0595, -0.1467,\n",
      "         -0.0216,  0.1590, -0.0791, -0.5878,  0.2140,  0.0116,  0.0842,  0.0181,\n",
      "         -0.2411,  0.1744, -0.0815,  0.3069, -0.1610,  0.1093,  0.1149, -0.2111,\n",
      "         -0.4566, -0.0443,  0.1989, -0.1942, -0.2622, -0.1263,  0.3670, -0.2812],\n",
      "        [-0.1144,  0.1658, -0.1994,  0.2232, -0.0683,  0.2219,  0.2655,  0.4258,\n",
      "         -0.0326, -0.1462, -0.0584,  0.2980, -0.0663,  0.1896, -0.0486,  0.3528,\n",
      "         -0.2598,  0.0683,  0.2263, -0.3286,  0.0065, -0.0126, -0.1758,  0.2649,\n",
      "         -0.1740,  0.2994, -0.0692, -0.3554,  0.0484, -0.0219, -0.4493,  0.4110],\n",
      "        [ 0.4281, -0.0311, -0.3707,  0.5601, -0.2563, -0.1194, -0.2108, -0.0102,\n",
      "         -0.1516, -0.0340, -0.2634,  0.4547, -0.1523,  0.6067, -0.4058,  0.1322,\n",
      "         -0.3815,  0.2264, -0.0823, -0.2132, -0.0130,  0.1347,  0.1836,  0.1278,\n",
      "         -0.0120, -0.0764, -0.3119, -0.1457,  0.3770, -0.0323, -0.4128, -0.1316]])), ('layers.2.bias', tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746]))])\n",
      "Args checkpoints/standard_model_for_pilot.pt\n",
      "[0] train metrics:{\"loss\": 1.6957053787638154, \"error\": 0.4350262478126823}\n",
      "Learning Rate : 0.001\n",
      "[0] test metrics:{\"loss\": 1.2201567613601685, \"error\": 0.2158}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.81 sec\n",
      "[1] train metrics:{\"loss\": 1.135481510219172, \"error\": 0.18546371135738687}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.7 sec\n",
      "[2] train metrics:{\"loss\": 1.0566367169994382, \"error\": 0.1521956503624698}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.53 sec\n",
      "[3] train metrics:{\"loss\": 1.0370397905877864, \"error\": 0.14057161903174736}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.59 sec\n",
      "[4] train metrics:{\"loss\": 1.0285105837671848, \"error\": 0.13388467627697692}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.5 sec\n",
      "[5] train metrics:{\"loss\": 1.0239834974342739, \"error\": 0.13053078910090826}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.67 sec\n",
      "[6] train metrics:{\"loss\": 1.0214508123054533, \"error\": 0.12780184984584617}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.58 sec\n",
      "[7] train metrics:{\"loss\": 1.0196682121115777, \"error\": 0.1277601866511124}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.75 sec\n",
      "[8] train metrics:{\"loss\": 1.0185629796230855, \"error\": 0.12644779601699857}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.71 sec\n",
      "[9] train metrics:{\"loss\": 1.0178989100958862, \"error\": 0.1261144904591284}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.84 sec\n",
      "[10] train metrics:{\"loss\": 1.0175718008781531, \"error\": 0.12505207899341722}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.05 sec\n",
      "[11] train metrics:{\"loss\": 1.0170587113515286, \"error\": 0.1247812682276477}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 7.12 sec\n",
      "[12] train metrics:{\"loss\": 1.016697402378289, \"error\": 0.1252187317723523}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.86 sec\n",
      "[13] train metrics:{\"loss\": 1.016376818798848, \"error\": 0.12488542621448212}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.03 sec\n",
      "[14] train metrics:{\"loss\": 1.0164363585892404, \"error\": 0.12386467794350471}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 7.02 sec\n",
      "[15] train metrics:{\"loss\": 1.0160483885343825, \"error\": 0.12453128905924506}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.48 sec\n",
      "[16] train metrics:{\"loss\": 1.0159531660292926, \"error\": 0.12482293142238148}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 7.1 sec\n",
      "[17] train metrics:{\"loss\": 1.015965955176559, \"error\": 0.12442713107241063}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 7.26 sec\n",
      "[18] train metrics:{\"loss\": 1.0159101984856695, \"error\": 0.1240104991250729}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.88 sec\n",
      "[19] train metrics:{\"loss\": 1.0157534404452986, \"error\": 0.12465627864344637}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 7.48 sec\n",
      "[20] train metrics:{\"loss\": 1.0156692651229822, \"error\": 0.12405216231980669}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.69 sec\n",
      "[21] train metrics:{\"loss\": 1.015744189621657, \"error\": 0.12451045746187818}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.97 sec\n",
      "[22] train metrics:{\"loss\": 1.015743130570143, \"error\": 0.12415632030664112}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.63 sec\n",
      "[23] train metrics:{\"loss\": 1.015751474828047, \"error\": 0.12469794183818016}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.84 sec\n",
      "[24] train metrics:{\"loss\": 1.0157363732977018, \"error\": 0.12426047829347554}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.63 sec\n",
      "[25] train metrics:{\"loss\": 1.0156331737730246, \"error\": 0.12367719356720273}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.02 sec\n",
      "[26] train metrics:{\"loss\": 1.0157239567924565, \"error\": 0.12380218315140405}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.12 sec\n",
      "[27] train metrics:{\"loss\": 1.0156740184009458, \"error\": 0.12392717273560537}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.76 sec\n",
      "[28] train metrics:{\"loss\": 1.0157745137292935, \"error\": 0.12438546787767686}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.43 sec\n",
      "[29] train metrics:{\"loss\": 1.0156028505246169, \"error\": 0.12455212065661195}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.56 sec\n",
      "[30] train metrics:{\"loss\": 1.015438807938419, \"error\": 0.12313557203566369}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.9 sec\n",
      "Pure training time: 186.37000000000003 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset mnist --model mlp --dataroot=data/MNIST/ --filters 1.0 --lr 0.001 \\\n",
    "--resume checkpoints/standard_model_for_pilot.pt --disable-bn \\\n",
    "--weight-decay 0.1 --batch-size 128 --epochs 31 --seed 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Note\n",
    "After running this cell, the code will generate a trace of checkpoints under the \"checkpoints\" folder.\n",
    "They are useful for later cell codes. But you could remove them after completing the experiment.\n",
    "\n",
    "Also, the code would also download a MNIST dataset in the data folder. You could remove it after the\n",
    "experiment.\n",
    "\n",
    "The code also generate a log file under \"logs\" folder if one wants to analyze using matlab. You could\n",
    "remove it after the experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Retain Model\n",
    "\n",
    "This code is used to train the retain model. The specific change compared to the upper cell (to train\n",
    "the original model) is the forget class command. This command refers datasets.get_loaders() in main.py\n",
    "and in dataset_multiclass.py, four functions are used to separate the retain class and the forget\n",
    "class. They are replace_indexes(), replace_class(), confuse_class(), get_loaders().\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_300_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3\n",
      "[Logging in mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_300_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_training]\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Replacing indexes [ 8526 16694 15152 29352   141 36509 37843 16926 35321 26042 21345  5714\n",
      " 47547 14437 39793 44980 45137  3897 35780 29999 33655 37420 40980 28992\n",
      "   105 40544 41016 46885 46091 40786  5543  7014 20505 25936 16792  2457\n",
      "  1600 13007  7760 15774 46362 33702 32877  2543 33599 32886 35244 29239\n",
      "  8640 23665 45315  3038 22738  3554  4458 36789 11462  2191 23706 10872\n",
      "  9290 32216 25081 12968 28129 20523  5261 16762 26382 19263 12728 37875\n",
      " 36911  7326 21202 31998 26810 28700 36488 42838  3180 24261 25761 13600\n",
      " 18425 29148 39305  4254  2025  4307 45980 28150 36331  8747 35060 28517\n",
      "  8694 12015 38188 36605 26116 12256 18607 11847  1442 19196 18989 33194\n",
      " 26487  5803   828 40152 11342 43196 20715 41802 14043  8865 20144 41373\n",
      " 47285  8202 21858  1815 22335  2739 16404  6882  9838 14297  4773 29745\n",
      "  8784 20420  9033 18865 39460 23585 14421 25902 31362 17568 47282 10213\n",
      " 10851 27398  9097 13317  3946 12763 22347 26179 27559 12416 12204 19720\n",
      " 28625 43760   991 18748  3274 11284 33410 22005  3957 23606 30636 39992\n",
      "  1264 25266 17560 31423 46872  6399  8159 35119  1818 44722 35781 44342\n",
      " 25267   634 46251  4819 19794 29351 33480 27853 45953 19391  8342 23363\n",
      " 10898 22639 11929 33139 20729 23386 14207 42742  6533 15472 42530 19571\n",
      " 22377 37233 37954 28603  5153 40736 28158 13824 24596 47089  4148 32854\n",
      " 44602 27694 42719 24075  6046 21712  7058  1106 33206 27058 40874 12132\n",
      " 27016 21465 25892  8743  8810 33435 33167 23515 47454 24149 46878 44043\n",
      " 12757 41548 24280 38149  3902 38656 29473  9135 19714 31691 38719 42099\n",
      " 41461  6753 39036 38931 19219 20760  6409 44396  3192 30070 21387 10447\n",
      " 47641  5579 43237 20422 15418 29575 24229 42701  5380  5442 12690 44635\n",
      " 35380 24691 28596 36012 38802  8417 18947 17449 14339 25511  4570 22447\n",
      " 12060 46231 41953 29310 37274 10157  1795 18569 36490 23796 29340 43197]\n",
      "Number of Classes: 10\n",
      "State OrderedDict([('layers.0.weight', tensor([[-0.0832, -0.0317,  0.0080,  ...,  0.0650, -0.0346, -0.0338],\n",
      "        [-0.0027, -0.0888, -0.0519,  ..., -0.0379,  0.0615,  0.0149],\n",
      "        [-0.1416, -0.0336,  0.0156,  ...,  0.0427,  0.0694,  0.0308],\n",
      "        ...,\n",
      "        [-0.0182, -0.0285,  0.0117,  ...,  0.0094, -0.0225, -0.0526],\n",
      "        [-0.0159,  0.0288, -0.0066,  ...,  0.0381,  0.0633,  0.0451],\n",
      "        [ 0.0131, -0.0608,  0.0516,  ..., -0.0093,  0.0415, -0.0130]])), ('layers.0.bias', tensor([ 0.2570,  0.5360, -0.9828, -0.2736, -0.2282,  0.3082,  0.4359, -0.1057,\n",
      "        -0.0857,  0.2738,  0.0112, -0.4476,  0.2455,  0.2458, -0.0411, -0.3458,\n",
      "        -0.4463,  0.1637, -0.5212,  0.0843,  0.1513, -0.1780, -0.6362,  0.2063,\n",
      "         0.4134,  0.2404, -0.3497, -0.2096, -0.0949, -0.2470,  0.0197,  0.4874])), ('layers.2.weight', tensor([[-0.3519, -0.2154, -0.3365, -0.1412,  0.4156,  0.1818,  0.0200, -0.0604,\n",
      "          0.2205,  0.2322, -0.0053, -0.1393, -0.2035, -0.0579,  0.0095, -0.1644,\n",
      "          0.2235,  0.3024,  0.2238, -0.7361,  0.2985,  0.1393,  0.1623, -0.0921,\n",
      "         -0.0720, -0.1394,  0.2537, -0.1786,  0.1402, -0.0607,  0.0045,  0.0832],\n",
      "        [ 0.3928, -0.1737, -0.1759, -0.4551,  0.2481, -0.4473, -0.0411, -0.2373,\n",
      "         -0.0809,  0.0645,  0.0849,  0.2062, -0.1421, -0.0616,  0.1801, -0.0840,\n",
      "         -0.2335, -0.0692,  0.1498, -0.0470, -0.1586, -0.1081,  0.0933, -0.2024,\n",
      "         -0.1436, -0.1707, -0.0688, -0.5912,  0.1219, -0.1256,  0.2843, -0.1910],\n",
      "        [ 0.4523, -0.3588,  0.0086,  0.0764,  0.1664,  0.4396,  0.0665,  0.4759,\n",
      "         -0.1288, -0.1356, -0.1838,  0.0269, -0.1764, -0.1239,  0.3496, -0.3435,\n",
      "          0.2170, -0.0702,  0.2358,  0.0587, -0.4519, -0.0437,  0.2893, -0.2968,\n",
      "          0.0510,  0.1216,  0.3035,  0.1648, -0.0432,  0.4584,  0.1138, -0.1609],\n",
      "        [-0.2260, -0.0343, -0.1534, -0.0083, -0.2569,  0.0590,  0.2407,  0.2322,\n",
      "         -0.0340,  0.2132,  0.1880,  0.2921, -0.0644, -0.0330,  0.4186,  0.4952,\n",
      "          0.0323,  0.1553, -0.1318, -0.1697,  0.2046, -0.2184,  0.0321, -0.3517,\n",
      "          0.3038, -0.0949, -0.1500,  0.1053, -0.0209, -0.1221, -0.1718, -0.0792],\n",
      "        [ 0.3664,  0.1804, -0.0120,  0.2229, -0.2088,  0.1287, -0.2451, -0.3353,\n",
      "          0.0897, -0.2442,  0.0131, -0.2590, -0.1019,  0.1473,  0.3632,  0.2329,\n",
      "          0.5305,  0.1337, -0.1440,  0.1620,  0.3382, -0.3171,  0.0806,  0.1881,\n",
      "          0.0109,  0.5281, -0.3445,  0.2525, -0.2200, -0.4710,  0.2022, -0.2743],\n",
      "        [ 0.1823, -0.0562, -0.2757, -0.0546, -0.1238, -0.1061,  0.0172, -0.0347,\n",
      "          0.4565,  0.1192, -0.0601,  0.2493, -0.2201,  0.0361,  0.0090,  0.2869,\n",
      "          0.0090, -0.2832, -0.0779, -0.2768, -0.3961, -0.1289,  0.1251, -0.0015,\n",
      "          0.2930,  0.1101,  0.0197,  0.2491,  0.0698,  0.3177,  0.0416,  0.0137],\n",
      "        [-0.3832,  0.2309, -0.1809,  0.1982,  0.0751,  0.0873, -0.1564,  0.0144,\n",
      "         -0.0449, -0.3521,  0.0023, -0.1973, -0.3833,  0.2016, -0.5147, -0.0191,\n",
      "          0.0122, -0.0809,  0.0038,  0.1643,  0.2994,  0.0281, -0.0899, -0.0444,\n",
      "          0.2220,  0.0072, -0.0604, -0.2090, -0.1963, -0.1330, -0.2076,  0.0046],\n",
      "        [-0.2165, -0.1100,  0.0688, -0.3747,  0.4035, -0.0398, -0.0595, -0.1467,\n",
      "         -0.0216,  0.1590, -0.0791, -0.5878,  0.2140,  0.0116,  0.0842,  0.0181,\n",
      "         -0.2411,  0.1744, -0.0815,  0.3069, -0.1610,  0.1093,  0.1149, -0.2111,\n",
      "         -0.4566, -0.0443,  0.1989, -0.1942, -0.2622, -0.1263,  0.3670, -0.2812],\n",
      "        [-0.1144,  0.1658, -0.1994,  0.2232, -0.0683,  0.2219,  0.2655,  0.4258,\n",
      "         -0.0326, -0.1462, -0.0584,  0.2980, -0.0663,  0.1896, -0.0486,  0.3528,\n",
      "         -0.2598,  0.0683,  0.2263, -0.3286,  0.0065, -0.0126, -0.1758,  0.2649,\n",
      "         -0.1740,  0.2994, -0.0692, -0.3554,  0.0484, -0.0219, -0.4493,  0.4110],\n",
      "        [ 0.4281, -0.0311, -0.3707,  0.5601, -0.2563, -0.1194, -0.2108, -0.0102,\n",
      "         -0.1516, -0.0340, -0.2634,  0.4547, -0.1523,  0.6067, -0.4058,  0.1322,\n",
      "         -0.3815,  0.2264, -0.0823, -0.2132, -0.0130,  0.1347,  0.1836,  0.1278,\n",
      "         -0.0120, -0.0764, -0.3119, -0.1457,  0.3770, -0.0323, -0.4128, -0.1316]])), ('layers.2.bias', tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746]))])\n",
      "Args checkpoints/standard_model_for_pilot.pt\n",
      "[0] train metrics:{\"loss\": 1.6955508042470524, \"error\": 0.4350262478126823}\n",
      "Learning Rate : 0.001\n",
      "[0] test metrics:{\"loss\": 1.220088168334961, \"error\": 0.2163}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 7.24 sec\n",
      "[1] train metrics:{\"loss\": 1.1354534324730707, \"error\": 0.18535955337055246}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.45 sec\n",
      "[2] train metrics:{\"loss\": 1.056726030901704, \"error\": 0.15227897675193733}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.32 sec\n",
      "[3] train metrics:{\"loss\": 1.0371734988102366, \"error\": 0.14057161903174736}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.26 sec\n",
      "[4] train metrics:{\"loss\": 1.028648248931466, \"error\": 0.13371802349804182}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.33 sec\n",
      "[5] train metrics:{\"loss\": 1.024162956063285, \"error\": 0.13086409465877843}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.53 sec\n",
      "[6] train metrics:{\"loss\": 1.0216317594711923, \"error\": 0.12803099741688193}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.4 sec\n",
      "[7] train metrics:{\"loss\": 1.0198602803487915, \"error\": 0.1279476710274144}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.44 sec\n",
      "[8] train metrics:{\"loss\": 1.0187525477630677, \"error\": 0.12640613282226482}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.36 sec\n",
      "[9] train metrics:{\"loss\": 1.0180947887193221, \"error\": 0.12623948004332972}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.6 sec\n",
      "[10] train metrics:{\"loss\": 1.0177762444918677, \"error\": 0.12536455295392052}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.92 sec\n",
      "[11] train metrics:{\"loss\": 1.017264149882537, \"error\": 0.12498958420131656}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.46 sec\n",
      "[12] train metrics:{\"loss\": 1.016896297669234, \"error\": 0.1252187317723523}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.87 sec\n",
      "[13] train metrics:{\"loss\": 1.0165873311497888, \"error\": 0.1253437213565536}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.41 sec\n",
      "[14] train metrics:{\"loss\": 1.0166354835376115, \"error\": 0.12396883593033914}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.49 sec\n",
      "[15] train metrics:{\"loss\": 1.0162662003658363, \"error\": 0.12498958420131656}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.54 sec\n",
      "[16] train metrics:{\"loss\": 1.0161743731997765, \"error\": 0.12490625781184901}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.51 sec\n",
      "[17] train metrics:{\"loss\": 1.0162088719817681, \"error\": 0.12465627864344637}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.29 sec\n",
      "[18] train metrics:{\"loss\": 1.016125079642017, \"error\": 0.12413548870927422}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.57 sec\n",
      "[19] train metrics:{\"loss\": 1.0159665824681379, \"error\": 0.12457295225397884}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.43 sec\n",
      "[20] train metrics:{\"loss\": 1.0158672984883483, \"error\": 0.12428130989084243}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.84 sec\n",
      "[21] train metrics:{\"loss\": 1.0159629398599763, \"error\": 0.12455212065661195}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.55 sec\n",
      "[22] train metrics:{\"loss\": 1.0159606663110543, \"error\": 0.12409382551454046}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.56 sec\n",
      "[23] train metrics:{\"loss\": 1.0159797972316056, \"error\": 0.12498958420131656}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.05 sec\n",
      "[24] train metrics:{\"loss\": 1.0159649011910175, \"error\": 0.12407299391717357}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.29 sec\n",
      "[25] train metrics:{\"loss\": 1.015828314502779, \"error\": 0.12384384634613782}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.0 sec\n",
      "[26] train metrics:{\"loss\": 1.0159221884906515, \"error\": 0.12384384634613782}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.55 sec\n",
      "[27] train metrics:{\"loss\": 1.0158880807669817, \"error\": 0.12388550954087159}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.79 sec\n",
      "[28] train metrics:{\"loss\": 1.0159736355884146, \"error\": 0.12469794183818016}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 6.03 sec\n",
      "[29] train metrics:{\"loss\": 1.0158080630834456, \"error\": 0.12457295225397884}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.71 sec\n",
      "[30] train metrics:{\"loss\": 1.0156555478547615, \"error\": 0.12323973002249812}\n",
      "Learning Rate : 0.001\n",
      "Epoch Time: 5.63 sec\n",
      "Pure training time: 176.37000000000003 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset mnist --model mlp --dataroot=data/MNIST/ --filters 1.0 --lr 0.001 \\\n",
    "--resume checkpoints/standard_model_for_pilot.pt --disable-bn \\\n",
    "--weight-decay 0.1 --batch-size 128 --epochs 31 \\\n",
    "--forget-class 0,1,2,3,4,5 --num-to-forget 300 --seed 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function will count the parameters in the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def parameter_count(model):\n",
    "    count=0\n",
    "    for p in model.parameters():\n",
    "        count+=np.prod(np.array(list(p.shape)))\n",
    "    print(f'Total Number of Parameters: {count}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importantly, the model object is an empty object in this. It is not initialized with our previous trained models.\n",
    "Here, we measure the parameters in the empty model object. (Original interpretation)\n",
    "\n",
    "Note: deepcopy will give you the entire object, while other methods only gives you the reference pointer (for references,\n",
    "see Java, C basics).\n",
    "\n",
    "Or, the model object is from the main.py code.\n",
    "\n",
    "I have not figured out this yet. I think the model object is from the main.py code and the later code use\n",
    "deep copy to make sure everything is aligned.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters: 33130\n"
     ]
    }
   ],
   "source": [
    "parameter_count(copy.deepcopy(model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize original model and retain model\n",
    "\n",
    "Here, we will use the checkpoints references to get the models that we have trained in the previous cells. The models\n",
    "that is initialized is in the cache of this jupyter notebook workflow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize three empty model objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_original = copy.deepcopy(model)\n",
    "model_retain = copy.deepcopy(model)\n",
    "model_pretrain = copy.deepcopy(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use checkpoint name to refer to the objects. Thus, here we initialize all the name parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "arch = args.model\n",
    "filters=args.filters\n",
    "arch_filters = arch +'_'+ str(filters).replace('.','_')\n",
    "augment = False\n",
    "dataset = args.dataset\n",
    "class_to_forget = args.forget_class\n",
    "init_checkpoint = f\"checkpoints/{args.name}_init.pt\"\n",
    "num_classes=args.num_classes\n",
    "num_to_forget = args.num_to_forget\n",
    "num_total = len(train_loader.dataset)\n",
    "num_to_retain = num_total - 300#num_to_forget\n",
    "seed = args.seed\n",
    "unfreeze_start = None\n",
    "learningrate=f\"lr_{str(args.lr).replace('.','_')}\"\n",
    "batch_size=f\"_bs_{str(args.batch_size)}\"\n",
    "lossfn=f\"_ls_{args.lossfn}\"\n",
    "wd=f\"_wd_{str(args.weight_decay).replace('.','_')}\"\n",
    "seed_name=f\"_seed_{args.seed}_\"\n",
    "num_tag = '' if num_to_forget is None else f'_num_{num_to_forget}'\n",
    "unfreeze_tag = '_' if unfreeze_start is None else f'_unfreeze_from_{unfreeze_start}_'\n",
    "augment_tag = '' if not augment else f'augment_'\n",
    "training_epochs=30\n",
    "log_dict={}\n",
    "log_dict['epoch']=training_epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we get the name of the model we want to get."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "m_name = f'checkpoints/{dataset}_{arch_filters}_forget_None{unfreeze_tag}{augment_tag}{learningrate}{batch_size}{lossfn}{wd}{seed_name}{training_epochs}.pt'\n",
    "m0_name = f'checkpoints/{dataset}_{arch_filters}_forget_{class_to_forget}{num_tag}{unfreeze_tag}{augment_tag}{learningrate}{batch_size}{lossfn}{wd}{seed_name}{training_epochs}.pt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make sure the names are correct."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/mnist_mlp_1_0_forget_None_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_30.pt\n"
     ]
    }
   ],
   "source": [
    "print(m_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_300_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_30.pt\n"
     ]
    }
   ],
   "source": [
    "print(m0_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/mnist_mlp_1_0_forget_[0, 1, 2, 3, 4, 5]_num_300_lr_0_001_bs_128_ls_ce_wd_0_1_seed_3_init.pt\n"
     ]
    }
   ],
   "source": [
    "print(init_checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get the original model, the retain, and the pretrained model that we used to train the original model and the\n",
    "retain model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_original.load_state_dict(torch.load(m_name))\n",
    "model_retain.load_state_dict(torch.load(m0_name))\n",
    "model_pretrain.load_state_dict(torch.load(init_checkpoint))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use parameters to see if we actually get the models from the checkpoints."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters: 33130\n",
      "Total Number of Parameters: 33130\n",
      "Total Number of Parameters: 33130\n"
     ]
    }
   ],
   "source": [
    "parameter_count(copy.deepcopy(model_original))\n",
    "parameter_count(copy.deepcopy(model_retain))\n",
    "parameter_count(copy.deepcopy(model_pretrain))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We analyze the parameters in the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Original: Parameter containing:\n",
      "tensor([ 0.2353,  0.7190,  0.5154,  0.0759,  0.2476, -0.0129,  0.2155,  0.3334,\n",
      "        -0.1101, -0.5481], requires_grad=True)\n",
      "Model_Pretrain Parameter containing:\n",
      "tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746], requires_grad=True)\n",
      "Model_Retain Parameter containing:\n",
      "tensor([ 0.2496,  0.6326,  0.5569,  0.1073,  0.2888, -0.0639,  0.1895,  0.2966,\n",
      "        -0.0117, -0.5746], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model_original.parameters():\n",
    "    p.data0 = p.data.clone()\n",
    "print(\"Model_Original:\", p)\n",
    "\n",
    "for p in model_pretrain.parameters():\n",
    "    p.data0 = p.data.clone()\n",
    "print(\"Model_Pretrain\", p)\n",
    "\n",
    "for p in model_pretrain.parameters():\n",
    "    p.data0 = p.data.clone()\n",
    "print(\"Model_Retain\", p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use distances to further analyze the three models. First, we define the distance function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# this method take the model object, then, iterate each parameter in the model.parameters() [this will\n",
    "# return the parameters set in the model object]. for each parameter object, we name another parameter\n",
    "# that is the same as the parameter, in named_parameters, later, in the distance function, we use\n",
    "# this copy of parameters, to measure the distance.\n",
    "def named_parameters_creat(model_):\n",
    "    for p in model_.parameters():\n",
    "        p.data0 = p.data.clone()\n",
    "\n",
    "def distance(model,model0):\n",
    "    distance=0\n",
    "    normalization=0\n",
    "\n",
    "    # Create named parameters in the model object as a copy of the original parameters\n",
    "    named_parameters_creat(model)\n",
    "    named_parameters_creat(model0)\n",
    "\n",
    "    # Calculate distance iterating through the named parameters\n",
    "    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n",
    "        space='  ' if 'bias' in k else ''\n",
    "        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n",
    "        current_norm=p.data0.pow(2).sum().item()\n",
    "        distance+=current_dist\n",
    "        normalization+=current_norm\n",
    "\n",
    "    print(f'Distance: {np.sqrt(distance)}')\n",
    "    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n",
    "    return 1.0*np.sqrt(distance/normalization)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compare original model and the retain model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.01723946476033257\n",
      "Normalized Distance: 0.0017215296878199434\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0017215296878199434"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(model_original,model_retain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compare the retain model and the pre-trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 2.838099898257449\n",
      "Normalized Distance: 0.304651585170325\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.304651585170325"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(model_pretrain,model_retain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compare the pretrain model and the original model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 2.838469428891656\n",
      "Normalized Distance: 0.30469125188309615\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.30469125188309615"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(model_pretrain, model_original)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Dataset for Unlearning\n",
    "\n",
    "explicit documentation has been add to datasets_multiclass.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "initialize retain and forget dataset batch size. And get forget dataset.\n",
    "\n",
    "Forget class has been originated when we train the model in main.py and it is given in jupyter notebook\n",
    "in our previous initialization section. To change the forget class, we need to re-run the main.py where\n",
    "we get the retain model.\n",
    "\n",
    "It is in the name."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confuse mode: False\n",
      "split mode: train\n",
      "confuse mode: False\n",
      "split mode: train\n",
      "Replacing indexes [ 8526 16694 15152 29352   141 36509 37843 16926 35321 26042 21345  5714\n",
      " 47547 14437 39793 44980 45137  3897 35780 29999 33655 37420 40980 28992\n",
      "   105 40544 41016 46885 46091 40786  5543  7014 20505 25936 16792  2457\n",
      "  1600 13007  7760 15774 46362 33702 32877  2543 33599 32886 35244 29239\n",
      "  8640 23665 45315  3038 22738  3554  4458 36789 11462  2191 23706 10872\n",
      "  9290 32216 25081 12968 28129 20523  5261 16762 26382 19263 12728 37875\n",
      " 36911  7326 21202 31998 26810 28700 36488 42838  3180 24261 25761 13600\n",
      " 18425 29148 39305  4254  2025  4307 45980 28150 36331  8747 35060 28517\n",
      "  8694 12015 38188 36605 26116 12256 18607 11847  1442 19196 18989 33194\n",
      " 26487  5803   828 40152 11342 43196 20715 41802 14043  8865 20144 41373\n",
      " 47285  8202 21858  1815 22335  2739 16404  6882  9838 14297  4773 29745\n",
      "  8784 20420  9033 18865 39460 23585 14421 25902 31362 17568 47282 10213\n",
      " 10851 27398  9097 13317  3946 12763 22347 26179 27559 12416 12204 19720\n",
      " 28625 43760   991 18748  3274 11284 33410 22005  3957 23606 30636 39992\n",
      "  1264 25266 17560 31423 46872  6399  8159 35119  1818 44722 35781 44342\n",
      " 25267   634 46251  4819 19794 29351 33480 27853 45953 19391  8342 23363\n",
      " 10898 22639 11929 33139 20729 23386 14207 42742  6533 15472 42530 19571\n",
      " 22377 37233 37954 28603  5153 40736 28158 13824 24596 47089  4148 32854\n",
      " 44602 27694 42719 24075  6046 21712  7058  1106 33206 27058 40874 12132\n",
      " 27016 21465 25892  8743  8810 33435 33167 23515 47454 24149 46878 44043\n",
      " 12757 41548 24280 38149  3902 38656 29473  9135 19714 31691 38719 42099\n",
      " 41461  6753 39036 38931 19219 20760  6409 44396  3192 30070 21387 10447\n",
      " 47641  5579 43237 20422 15418 29575 24229 42701  5380  5442 12690 44635\n",
      " 35380 24691 28596 36012 38802  8417 18947 17449 14339 25511  4570 22447\n",
      " 12060 46231 41953 29310 37274 10157  1795 18569 36490 23796 29340 43197]\n"
     ]
    }
   ],
   "source": [
    "args.retain_bs = 32\n",
    "args.forget_bs = 64\n",
    "train_loader_full, valid_loader_full, test_loader_full   = datasets.get_loaders(dataset, batch_size=args.batch_size, seed=seed, root=args.dataroot, augment=False, shuffle=True)\n",
    "marked_loader, _, _ = datasets.get_loaders(dataset, class_to_replace=class_to_forget, num_indexes_to_replace=num_to_forget, only_mark=True, batch_size=1, seed=seed, root=args.dataroot, augment=False, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case, we define a function that puts the dataset into the data loader."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def replace_loader_dataset(data_loader, dataset, batch_size=args.batch_size, seed=1, shuffle=True):\n",
    "    manual_seed(seed)\n",
    "    loader_args = {'num_workers': 0, 'pin_memory': False}\n",
    "    def _init_fn(worker_id):\n",
    "        np.random.seed(int(seed))\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,num_workers=0,pin_memory=True,shuffle=shuffle)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get forget dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "forget_dataset = copy.deepcopy(marked_loader.dataset)\n",
    "marked = forget_dataset.targets < 0\n",
    "forget_dataset.data = forget_dataset.data[marked]\n",
    "forget_dataset.targets = - forget_dataset.targets[marked] - 1\n",
    "forget_loader = replace_loader_dataset(train_loader_full, forget_dataset, batch_size=args.forget_bs, seed=seed, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get retain dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "retain_dataset = copy.deepcopy(marked_loader.dataset)\n",
    "marked = retain_dataset.targets >= 0\n",
    "retain_dataset.data = retain_dataset.data[marked]\n",
    "retain_dataset.targets = retain_dataset.targets[marked]\n",
    "retain_loader = replace_loader_dataset(train_loader_full, retain_dataset, batch_size=args.retain_bs, seed=seed, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make sure everything is working"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "47704\n",
      "10000\n",
      "48004\n",
      "{5: 4337, 4: 4674, 9: 4760, 2: 4767, 1: 5394, 3: 4905, 6: 4735, 7: 5012, 8: 4681, 0: 4739}\n"
     ]
    }
   ],
   "source": [
    "assert(len(forget_dataset) + len(retain_dataset) == len(train_loader_full.dataset))\n",
    "print (len(forget_loader.dataset))\n",
    "print (len(retain_loader.dataset))\n",
    "print (len(test_loader_full.dataset))\n",
    "print (len(train_loader_full.dataset))\n",
    "from collections import Counter\n",
    "print(dict(Counter(train_loader_full.dataset.targets)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning with Retain Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function calculates the L2 regularization penalty term for the model's weights by comparing them to the initial\n",
    " (untrained) model's weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def l2_penalty(model,model_init,weight_decay):\n",
    "    l2_loss = 0\n",
    "    for (k,p),(k_init,p_init) in zip(model.named_parameters(),model_init.named_parameters()):\n",
    "        if p.requires_grad:\n",
    "            l2_loss += (p-p_init).pow(2).sum()\n",
    "    l2_loss *= (weight_decay/2.)\n",
    "    return l2_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define training function for fine-tune."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "def run_finetune_train_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, epoch=int):\n",
    "\n",
    "    # you set the model's internal state to indicate that it's being used for inference or evaluation, not for training.\n",
    "    # It ensures that certain layers and behaviors in the model are adjusted for this purpose\n",
    "    model.eval()\n",
    "\n",
    "    # Computes and stores the average and current value, defined in utils.py\n",
    "    metrics = AverageMeter()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for idx, batch in enumerate(tqdm(data_loader, leave=False)):\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            input, target = batch\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target) + l2_penalty(model,model_init,args.weight_decay)\n",
    "            metrics.update(n=input.size(0), loss=loss_fn(output,target).item(), error=get_error(output, target))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return metrics.avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def finetune(model: nn.Module, data_loader: torch.utils.data.DataLoader, lr=0.01, epochs=10, quiet=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        run_finetune_train_epoch(model, model_init, data_loader, loss_fn, optimizer, epoch=epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8187a97b90c446cabc5a37e19843ed87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35d832e830f04702977d3a926bea8b31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "077d244d0c8141ad9734a43e7c41d9f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9a9f9a0295e4a73a6c398d0d61fb78a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e098f673c444f9ba5d7180841726979"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f7b6aa643a5460ea8c48b5f9ea66e99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd8e342901f0449e97642e9a837b7f6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a98ccceb2515475381a4263802129494"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24ec63e8327246a9810362e1b6284897"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c918e0f131604b1e93ebe9caca5dc24b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = copy.deepcopy(model)\n",
    "retain_loader = replace_loader_dataset(train_loader_full,retain_dataset, seed=seed, batch_size=args.batch_size, shuffle=True)\n",
    "finetune(model_ft, retain_loader, epochs=10, quiet=True, lr=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Negative Gradients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def negative_grad(model: nn.Module, data_loader: torch.utils.data.DataLoader, forget_loader: torch.utils.data.DataLoader, alpha: float, lr=0.01, epochs=10):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        run_neggrad_epoch(model, model_init, data_loader, forget_loader, alpha, loss_fn, optimizer, epoch=epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def run_neggrad_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader,\n",
    "                    forget_loader: torch.utils.data.DataLoader,\n",
    "                    alpha: float,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, epoch: int):\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for idx, (batch_retain,batch_forget) in enumerate(tqdm(zip(data_loader,cycle(forget_loader)), leave=False)):\n",
    "            batch_retain = [tensor.to(next(model.parameters()).device) for tensor in batch_retain]\n",
    "            batch_forget = [tensor.to(next(model.parameters()).device) for tensor in batch_forget]\n",
    "            input_r, target_r = batch_retain\n",
    "            input_f, target_f = batch_forget\n",
    "            output_r = model(input_r)\n",
    "            output_f = model(input_f)\n",
    "            # Negative Gradient Loss Function\n",
    "            loss = alpha*(loss_fn(output_r, target_r) + l2_penalty(model,model_init,args.weight_decay)) - (1-alpha)*loss_fn(output_f, target_f)\n",
    "            metrics.update(n=input_r.size(0), loss=loss_fn(output_r,target_r).item(), error=get_error(output_r, target_r))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return metrics.avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3829af5c65ee471aa385e315dad8cd16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa74f4ed2898484fa7335de0339517ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1710a33cd175414ab6756a78883c3fb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4324fb9e0119409cbaf0b1b814d1e54b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5580441617f42dc8b6641f7ba48d611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "254bf9a5c28249ac9169da6114383326"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fe5249e8cb34867b76ab500167380a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8e2b240b0504338876a8d73d94153fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aca10c6d9b8a4d66969ea6fa9fa2a1a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8082fa580ea54950abd37747fa304e9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args.ng_alpha = 0.95\n",
    "args.ng_epochs = 10\n",
    "args.ng_lr = 0.01\n",
    "model_negative_gradient = copy.deepcopy(model)\n",
    "negative_grad(model_negative_gradient, retain_loader, forget_loader, alpha=args.ng_alpha, epochs=args.ng_epochs, lr=args.ng_lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fisher Forgetting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model_fisher_on_original = copy.deepcopy(model_original)\n",
    "model_fisher_on_pretrained = copy.deepcopy(model_pretrain)\n",
    "for p in itertools.chain(model_fisher_on_original.parameters(), model_fisher_on_pretrained.parameters()):\n",
    "    p.data0 = copy.deepcopy(p.data.clone())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def hessian(data_set, model):\n",
    "    model.eval()\n",
    "    train_loader = torch.utils.data.DataLoader(data_set, batch_size=1, shuffle=False)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for p in model.parameters():\n",
    "        p.grad_acc = 0\n",
    "        p.grad2_acc = 0\n",
    "    for data, orig_target in tqdm(train_loader):\n",
    "        data, orig_target = data.to(args.device), orig_target.to(args.device)\n",
    "        output = model(data)\n",
    "        prob = F.softmax(output, dim=-1).data\n",
    "        for y in range(output.shape[1]):\n",
    "            target = torch.empty_like(orig_target).fill_(y)\n",
    "            loss = loss_fn(output, target)\n",
    "            model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            for p in model.parameters():\n",
    "                if p.requires_grad:\n",
    "                    p.grad_acc += (orig_target == target).float() * p.grad.data\n",
    "                    p.grad2_acc += prob[:, y] * p.grad.data.pow(2)\n",
    "    for p in model.parameters():\n",
    "        p.grad_acc /= len(train_loader)\n",
    "        p.grad2_acc /= len(train_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_mean_var(p, is_base_dist=False, alpha=3e-6):\n",
    "    var = copy.deepcopy(1./(p.grad2_acc+1e-8))\n",
    "    var = var.clamp(max=1e3)\n",
    "    if p.size(0) == num_classes:\n",
    "        var = var.clamp(max=1e2)\n",
    "    var = alpha * var\n",
    "    if p.ndim > 1:\n",
    "        var = var.mean(dim=1, keepdim=True).expand_as(p).clone()\n",
    "    if not is_base_dist:\n",
    "        mu = copy.deepcopy(p.data0.clone())\n",
    "    else:\n",
    "        mu = copy.deepcopy(p.data0.clone())\n",
    "    if p.size(0) == num_classes and num_to_forget is None:\n",
    "        mu[class_to_forget] = 0\n",
    "        var[class_to_forget] = 0.0001\n",
    "    if p.size(0) == num_classes:\n",
    "        # Last layer\n",
    "        var *= 10\n",
    "    elif p.ndim == 1:\n",
    "        # BatchNorm\n",
    "        var *= 10\n",
    "    return mu, var\n",
    "def kl_divergence_fisher(mu0, var0, mu1, var1):\n",
    "    return ((mu1 - mu0).pow(2)/var0 + var1/var0 - torch.log(var1/var0) - 1).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/47704 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b7f20206974f0194d6ffeb30032f15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47704 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26f70ebcfbc343319e1dc59c525b7ba7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hessian(retain_loader.dataset, model_fisher_on_original)\n",
    "hessian(retain_loader.dataset, model_fisher_on_pretrained)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight 84076.4\n",
      "layers.0.bias 2873.1\n",
      "layers.2.weight 47325.3\n",
      "layers.2.bias 1490.9\n",
      "Total: 135765.6915283203\n"
     ]
    }
   ],
   "source": [
    "# Computes the amount of information not forgotten at all layers using the given alpha\n",
    "\n",
    "alpha = 1e-7\n",
    "total_kl = 0\n",
    "torch.manual_seed(seed)\n",
    "for (k, p), (k0, p0) in zip(model_fisher_on_original.named_parameters(), model_fisher_on_pretrained.named_parameters()):\n",
    "    mu0, var0 = get_mean_var(p, False, alpha=alpha)\n",
    "    mu1, var1 = get_mean_var(p0, True, alpha=alpha)\n",
    "    kl = kl_divergence_fisher(mu0, var0, mu1, var1).item()\n",
    "    total_kl += kl\n",
    "    print(k, f'{kl:.1f}')\n",
    "print(\"Total:\", total_kl)\n",
    "log_dict['fisher_info']=total_kl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "fisher_dir = []\n",
    "alpha = 1e-6\n",
    "torch.manual_seed(seed)\n",
    "for i, p in enumerate(model_fisher_on_original.parameters()):\n",
    "    mu, var = get_mean_var(p, False, alpha=alpha)\n",
    "    p.data = mu + var.sqrt() * torch.empty_like(p.data0).normal_()\n",
    "    fisher_dir.append(var.sqrt().view(-1).cpu().detach().numpy())\n",
    "for i, p in enumerate(model_fisher_on_pretrained.parameters()):\n",
    "    mu, var = get_mean_var(p, False, alpha=alpha)\n",
    "    p.data = mu + var.sqrt() * torch.empty_like(p.data0).normal_()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.02581256, 0.02581256, 0.02581256, ..., 0.02663056, 0.02663056,\n",
      "       0.02663056], dtype=float32), array([0.01120348, 0.01925958, 0.1       , 0.01317205, 0.01422691,\n",
      "       0.01722947, 0.01903657, 0.01380538, 0.02635177, 0.01516579,\n",
      "       0.08655989, 0.1       , 0.02218431, 0.01602788, 0.01262214,\n",
      "       0.01443681, 0.01447882, 0.01836829, 0.1       , 0.01328962,\n",
      "       0.01359364, 0.1       , 0.05437382, 0.01596257, 0.01382485,\n",
      "       0.01617381, 0.01868689, 0.01820576, 0.03456153, 0.01573715,\n",
      "       0.01481964, 0.01508825], dtype=float32), array([0.02052041, 0.02052041, 0.02052041, 0.02052041, 0.02052041,\n",
      "       0.02052041, 0.02052041, 0.02052041, 0.02052041, 0.02052041,\n",
      "       0.02052041, 0.02052041, 0.02052041, 0.02052041, 0.02052041,\n",
      "       0.02052041, 0.02052041, 0.02052041, 0.02052041, 0.02052041,\n",
      "       0.02052041, 0.02052041, 0.02052041, 0.02052041, 0.02052041,\n",
      "       0.02052041, 0.02052041, 0.02052041, 0.02052041, 0.02052041,\n",
      "       0.02052041, 0.02052041, 0.02422591, 0.02422591, 0.02422591,\n",
      "       0.02422591, 0.02422591, 0.02422591, 0.02422591, 0.02422591,\n",
      "       0.02422591, 0.02422591, 0.02422591, 0.02422591, 0.02422591,\n",
      "       0.02422591, 0.02422591, 0.02422591, 0.02422591, 0.02422591,\n",
      "       0.02422591, 0.02422591, 0.02422591, 0.02422591, 0.02422591,\n",
      "       0.02422591, 0.02422591, 0.02422591, 0.02422591, 0.02422591,\n",
      "       0.02422591, 0.02422591, 0.02422591, 0.02422591, 0.0205225 ,\n",
      "       0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 ,\n",
      "       0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 ,\n",
      "       0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 ,\n",
      "       0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 ,\n",
      "       0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 ,\n",
      "       0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 , 0.0205225 ,\n",
      "       0.0205225 , 0.01931648, 0.01931648, 0.01931648, 0.01931648,\n",
      "       0.01931648, 0.01931648, 0.01931648, 0.01931648, 0.01931648,\n",
      "       0.01931648, 0.01931648, 0.01931648, 0.01931648, 0.01931648,\n",
      "       0.01931648, 0.01931648, 0.01931648, 0.01931648, 0.01931648,\n",
      "       0.01931648, 0.01931648, 0.01931648, 0.01931648, 0.01931648,\n",
      "       0.01931648, 0.01931648, 0.01931648, 0.01931648, 0.01931648,\n",
      "       0.01931648, 0.01931648, 0.01931648, 0.02009408, 0.02009408,\n",
      "       0.02009408, 0.02009408, 0.02009408, 0.02009408, 0.02009408,\n",
      "       0.02009408, 0.02009408, 0.02009408, 0.02009408, 0.02009408,\n",
      "       0.02009408, 0.02009408, 0.02009408, 0.02009408, 0.02009408,\n",
      "       0.02009408, 0.02009408, 0.02009408, 0.02009408, 0.02009408,\n",
      "       0.02009408, 0.02009408, 0.02009408, 0.02009408, 0.02009408,\n",
      "       0.02009408, 0.02009408, 0.02009408, 0.02009408, 0.02009408,\n",
      "       0.01841258, 0.01841258, 0.01841258, 0.01841258, 0.01841258,\n",
      "       0.01841258, 0.01841258, 0.01841258, 0.01841258, 0.01841258,\n",
      "       0.01841258, 0.01841258, 0.01841258, 0.01841258, 0.01841258,\n",
      "       0.01841258, 0.01841258, 0.01841258, 0.01841258, 0.01841258,\n",
      "       0.01841258, 0.01841258, 0.01841258, 0.01841258, 0.01841258,\n",
      "       0.01841258, 0.01841258, 0.01841258, 0.01841258, 0.01841258,\n",
      "       0.01841258, 0.01841258, 0.02130533, 0.02130533, 0.02130533,\n",
      "       0.02130533, 0.02130533, 0.02130533, 0.02130533, 0.02130533,\n",
      "       0.02130533, 0.02130533, 0.02130533, 0.02130533, 0.02130533,\n",
      "       0.02130533, 0.02130533, 0.02130533, 0.02130533, 0.02130533,\n",
      "       0.02130533, 0.02130533, 0.02130533, 0.02130533, 0.02130533,\n",
      "       0.02130533, 0.02130533, 0.02130533, 0.02130533, 0.02130533,\n",
      "       0.02130533, 0.02130533, 0.02130533, 0.02130533, 0.02164388,\n",
      "       0.02164388, 0.02164388, 0.02164388, 0.02164388, 0.02164388,\n",
      "       0.02164388, 0.02164388, 0.02164388, 0.02164388, 0.02164388,\n",
      "       0.02164388, 0.02164388, 0.02164388, 0.02164388, 0.02164388,\n",
      "       0.02164388, 0.02164388, 0.02164388, 0.02164388, 0.02164388,\n",
      "       0.02164388, 0.02164388, 0.02164388, 0.02164388, 0.02164388,\n",
      "       0.02164388, 0.02164388, 0.02164388, 0.02164388, 0.02164388,\n",
      "       0.02164388, 0.01873223, 0.01873223, 0.01873223, 0.01873223,\n",
      "       0.01873223, 0.01873223, 0.01873223, 0.01873223, 0.01873223,\n",
      "       0.01873223, 0.01873223, 0.01873223, 0.01873223, 0.01873223,\n",
      "       0.01873223, 0.01873223, 0.01873223, 0.01873223, 0.01873223,\n",
      "       0.01873223, 0.01873223, 0.01873223, 0.01873223, 0.01873223,\n",
      "       0.01873223, 0.01873223, 0.01873223, 0.01873223, 0.01873223,\n",
      "       0.01873223, 0.01873223, 0.01873223, 0.01990644, 0.01990644,\n",
      "       0.01990644, 0.01990644, 0.01990644, 0.01990644, 0.01990644,\n",
      "       0.01990644, 0.01990644, 0.01990644, 0.01990644, 0.01990644,\n",
      "       0.01990644, 0.01990644, 0.01990644, 0.01990644, 0.01990644,\n",
      "       0.01990644, 0.01990644, 0.01990644, 0.01990644, 0.01990644,\n",
      "       0.01990644, 0.01990644, 0.01990644, 0.01990644, 0.01990644,\n",
      "       0.01990644, 0.01990644, 0.01990644, 0.01990644, 0.01990644],\n",
      "      dtype=float32), array([0.01689437, 0.01538881, 0.01409102, 0.01357729, 0.01368666,\n",
      "       0.01339482, 0.01553793, 0.01521458, 0.01207013, 0.01319715],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(fisher_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model_fisher = copy.deepcopy(model_fisher_on_original)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CF-K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def CF_K(model: nn.Module, data_loader: torch.utils.data.DataLoader, args, lr=0.01, epochs=10):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        sgda_adjust_learning_rate(epoch, args, optimizer)\n",
    "        run_CF_K_epoch(model, model_init, data_loader, loss_fn, optimizer, epoch=epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def run_CF_K_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, epoch: int):\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for idx, batch in enumerate(tqdm(data_loader, leave=False)):\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            input, target = batch\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target) + l2_penalty(model,model_init,args.weight_decay)\n",
    "            metrics.update(n=input.size(0), loss=loss_fn(output,target).item(), error=get_error(output, target))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return metrics.avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF-K is not applicable\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCF-K is not applicable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 19\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n\u001B[1;32m     21\u001B[0m CF_K(model_cfk, retain_loader, args\u001B[38;5;241m=\u001B[39margs, epochs\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mcfk_epochs, lr\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mcfk_lr)\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args.lr_decay_epochs = [10,15,20]\n",
    "args.cfk_lr = 0.01\n",
    "args.cfk_epochs = 10\n",
    "model_cfk = copy.deepcopy(model)\n",
    "\n",
    "for param in model_cfk.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "if args.model == 'allcnn':\n",
    "    layers = [9]\n",
    "    for k in layers:\n",
    "        for param in model_cfk.features[k].parameters():\n",
    "            param.requires_grad_(True)\n",
    "elif args.model == \"resnet\":\n",
    "    for param in model_cfk.layer4.parameters():\n",
    "        param.requires_grad_(True)\n",
    "else:\n",
    "    print(\"CF-K is not applicable\")\n",
    "    raise NotImplementedError\n",
    "\n",
    "CF_K(model_cfk, retain_loader, args=args, epochs=args.cfk_epochs, lr=args.cfk_lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EU-K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def run_eu_k_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, split: str, epoch: int, ignore_index=None,\n",
    "                    negative_gradient=False, negative_multiplier=-1, random_labels=False,\n",
    "                    quiet=False,delta_w=None,scrub_act=False):\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    with torch.set_grad_enabled(split != 'test'):\n",
    "        for idx, batch in enumerate(tqdm(data_loader, leave=False)):\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            input, target = batch\n",
    "            output = model(input)\n",
    "            if split=='test' and scrub_act:\n",
    "                G = []\n",
    "                for cls in range(num_classes):\n",
    "                    grads = torch.autograd.grad(output[0,cls],model.parameters(),retain_graph=True)\n",
    "                    grads = torch.cat([g.view(-1) for g in grads])\n",
    "                    G.append(grads)\n",
    "                grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=False)\n",
    "                G = torch.stack(G).pow(2)\n",
    "                delta_f = torch.matmul(G,delta_w)\n",
    "                output += delta_f.sqrt()*torch.empty_like(delta_f).normal_()\n",
    "            loss = loss_fn(output, target) + l2_penalty(model,model_init,args.weight_decay)\n",
    "            metrics.update(n=input.size(0), loss=loss_fn(output,target).item(), error=get_error(output, target))\n",
    "\n",
    "            if split != 'test':\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    if not quiet:\n",
    "        log_metrics(split, metrics, epoch)\n",
    "    return metrics.avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def EU_K(model: nn.Module, data_loader: torch.utils.data.DataLoader, args, lr=0.01, epochs=10, quiet=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        sgda_adjust_learning_rate(epoch, args, optimizer)\n",
    "        run_eu_k_epoch(model, model_init, data_loader, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU_K is not applicable\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 72\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEU_K is not applicable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args.lr_decay_epochs = [10,15,20]\n",
    "args.euk_lr = 0.01\n",
    "args.euk_epochs = training_epochs\n",
    "model_euk = copy.deepcopy(model)\n",
    "\n",
    "for param in model_euk.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "if args.model == 'allcnn':\n",
    "    with torch.no_grad():\n",
    "        for k in layers:\n",
    "            for i in range(0,3):\n",
    "                try:\n",
    "                    model_euk.features[k][i].weight.copy_(model_initial.features[k][i].weight)\n",
    "                except:\n",
    "                    print (\"block {}, layer {} does not have weights\".format(k,i))\n",
    "                try:\n",
    "                    model_euk.features[k][i].bias.copy_(model_initial.features[k][i].bias)\n",
    "                except:\n",
    "                    print (\"block {}, layer {} does not have bias\".format(k,i))\n",
    "        model_euk.classifier[0].weight.copy_(model_initial.classifier[0].weight)\n",
    "        model_euk.classifier[0].bias.copy_(model_initial.classifier[0].bias)\n",
    "\n",
    "    for k in layers:\n",
    "        for param in model_euk.features[k].parameters():\n",
    "            param.requires_grad_(True)\n",
    "\n",
    "elif args.model == \"resnet\":\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,2):\n",
    "            try:\n",
    "                model_euk.layer4[i].bn1.weight.copy_(model_initial.layer4[i].bn1.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].bn1.bias.copy_(model_initial.layer4[i].bn1.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv1.weight.copy_(model_initial.layer4[i].conv1.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv1.bias.copy_(model_initial.layer4[i].conv1.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "\n",
    "            try:\n",
    "                model_euk.layer4[i].bn2.weight.copy_(model_initial.layer4[i].bn2.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].bn2.bias.copy_(model_initial.layer4[i].bn2.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv2.weight.copy_(model_initial.layer4[i].conv2.weight)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have weight\".format(i))\n",
    "            try:\n",
    "                model_euk.layer4[i].conv2.bias.copy_(model_initial.layer4[i].conv2.bias)\n",
    "            except:\n",
    "                print (\"block 4, layer {} does not have bias\".format(i))\n",
    "\n",
    "        model_euk.layer4[0].shortcut[0].weight.copy_(model_initial.layer4[0].shortcut[0].weight)\n",
    "\n",
    "    for param in model_euk.layer4.parameters():\n",
    "        param.requires_grad_(True)\n",
    "\n",
    "else:\n",
    "    print(\"EU_K is not applicable\")\n",
    "    raise NotImplementedError"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/373 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a4bc6de9c674243ab65f1617f697e22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m EU_K(model_euk, retain_loader, epochs\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39meuk_epochs, quiet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, lr\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39meuk_lr, args\u001B[38;5;241m=\u001B[39margs)\n",
      "Cell \u001B[0;32mIn[43], line 7\u001B[0m, in \u001B[0;36mEU_K\u001B[0;34m(model, data_loader, args, lr, epochs, quiet)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      6\u001B[0m     sgda_adjust_learning_rate(epoch, args, optimizer)\n\u001B[0;32m----> 7\u001B[0m     run_eu_k_epoch(model, model_init, data_loader, loss_fn, optimizer, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, epoch\u001B[38;5;241m=\u001B[39mepoch, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, quiet\u001B[38;5;241m=\u001B[39mquiet)\n",
      "Cell \u001B[0;32mIn[42], line 28\u001B[0m, in \u001B[0;36mrun_eu_k_epoch\u001B[0;34m(model, model_init, data_loader, loss_fn, optimizer, split, epoch, ignore_index, negative_gradient, negative_multiplier, random_labels, quiet, delta_w, scrub_act)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m split \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     27\u001B[0m             model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 28\u001B[0m             loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     29\u001B[0m             optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m quiet:\n",
      "File \u001B[0;32m~/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    489\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001B[1;32m    202\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "EU_K(model_euk, retain_loader, epochs=args.euk_epochs, quiet=True, lr=args.euk_lr, args=args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SCRUB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "args.optim = 'adam'\n",
    "args.gamma = 1\n",
    "args.alpha = 0.5\n",
    "args.beta = 0\n",
    "args.smoothing = 0.5\n",
    "args.msteps = 3\n",
    "args.clip = 0.2\n",
    "args.sstart = 10\n",
    "args.kd_T = 2\n",
    "args.distill = 'kd'\n",
    "\n",
    "args.sgda_epochs = 10\n",
    "args.sgda_learning_rate = 0.0005\n",
    "args.lr_decay_epochs = [5,8,9]\n",
    "args.lr_decay_rate = 0.1\n",
    "args.sgda_weight_decay = 0.1#5e-4\n",
    "args.sgda_momentum = 0.9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "teacher = copy.deepcopy(model)\n",
    "student = copy.deepcopy(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "model_t = copy.deepcopy(teacher)\n",
    "model_s = copy.deepcopy(student)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "def avg_fn(averaged_model_parameter, model_parameter, num_averaged): return (\n",
    "    1 - beta) * averaged_model_parameter + beta * model_parameter\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(\n",
    "    model_s, avg_fn=avg_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "module_list = nn.ModuleList([])\n",
    "module_list.append(model_s)\n",
    "trainable_list = nn.ModuleList([])\n",
    "trainable_list.append(model_s)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_div = DistillKL(args.kd_T)\n",
    "criterion_kd = DistillKL(args.kd_T)\n",
    "\n",
    "\n",
    "criterion_list = nn.ModuleList([])\n",
    "criterion_list.append(criterion_cls)    # classification loss\n",
    "criterion_list.append(criterion_div)    # KL divergence loss, original knowledge distillation\n",
    "criterion_list.append(criterion_kd)     # other knowledge distillation loss\n",
    "\n",
    "# optimizer\n",
    "if args.optim == \"sgd\":\n",
    "    optimizer = optim.SGD(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          momentum=args.sgda_momentum,\n",
    "                          weight_decay=args.sgda_weight_decay)\n",
    "elif args.optim == \"adam\":\n",
    "    optimizer = optim.Adam(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          weight_decay=args.sgda_weight_decay)\n",
    "elif args.optim == \"rmsp\":\n",
    "    optimizer = optim.RMSprop(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          momentum=args.sgda_momentum,\n",
    "                          weight_decay=args.sgda_weight_decay)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "module_list.append(model_t)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    module_list.cuda()\n",
    "    criterion_list.cuda()\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    cudnn.benchmark = True\n",
    "    swa_model.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> scrub unlearning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 87.728 \n",
      "maximize loss: 0.07\t minimize loss: 1.88\t train_acc: 87.7284927368164\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.787 \n",
      "maximize loss: 1.48\t minimize loss: 2.11\t train_acc: 87.78718566894531\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.823 \n",
      "maximize loss: 1.49\t minimize loss: 2.11\t train_acc: 87.82282257080078\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.812 \n",
      "maximize loss: 0.00\t minimize loss: 2.11\t train_acc: 87.81233978271484\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.743 \n",
      "maximize loss: 0.00\t minimize loss: 2.11\t train_acc: 87.7431640625\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.879 \n",
      "maximize loss: 0.00\t minimize loss: 2.10\t train_acc: 87.87942504882812\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.926 \n",
      "maximize loss: 0.00\t minimize loss: 2.09\t train_acc: 87.925537109375\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.938 \n",
      "maximize loss: 0.00\t minimize loss: 2.09\t train_acc: 87.93811798095703\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.959 \n",
      "maximize loss: 0.00\t minimize loss: 2.09\t train_acc: 87.9590835571289\n",
      "==> scrub unlearning ...\n",
      " * Acc@1 87.965 \n",
      "maximize loss: 0.00\t minimize loss: 2.09\t train_acc: 87.96537017822266\n"
     ]
    }
   ],
   "source": [
    "acc_rs = []\n",
    "acc_fs = []\n",
    "acc_ts = []\n",
    "for epoch in range(1, args.sgda_epochs + 1):\n",
    "\n",
    "    lr = sgda_adjust_learning_rate(epoch, args, optimizer)\n",
    "\n",
    "    print(\"==> scrub unlearning ...\")\n",
    "\n",
    "    acc_r, acc5_r, loss_r = validate(retain_loader, model_s, criterion_cls, args, True)\n",
    "    acc_f, acc5_f, loss_f = validate(forget_loader, model_s, criterion_cls, args, True)\n",
    "    acc_rs.append(100-acc_r.item())\n",
    "    acc_fs.append(100-acc_f.item())\n",
    "\n",
    "    maximize_loss = 0\n",
    "    if epoch <= args.msteps:\n",
    "        maximize_loss = train_distill(epoch, forget_loader, module_list, swa_model, criterion_list, optimizer, args, \"maximize\")\n",
    "    train_acc, train_loss = train_distill(epoch, retain_loader, module_list, swa_model, criterion_list, optimizer, args, \"minimize\",)\n",
    "    if epoch >= args.sstart:\n",
    "        swa_model.update_parameters(model_s)\n",
    "\n",
    "    print (\"maximize loss: {:.2f}\\t minimize loss: {:.2f}\\t train_acc: {}\".format(maximize_loss, train_loss, train_acc))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "indices = list(range(0,len(acc_rs)))\n",
    "plt.plot(indices, acc_rs, marker='*', alpha=1, label='retain-set')\n",
    "plt.plot(indices, acc_fs, marker='o', alpha=1, label='forget-set')\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.title('scrub retain- and forget- set error',size=18)\n",
    "plt.xlabel('epoch',size=14)\n",
    "plt.ylabel('error',size=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
